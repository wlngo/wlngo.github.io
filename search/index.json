[{"content":"私有内网Oss Alist qb ","date":"2025-03-11T00:00:00Z","permalink":"https://wlngo.github.io/p/%E5%AF%BC%E8%88%AA/","title":"导航"},{"content":"当然可以！以下是整理成Markdown格式的总结文档，详细说明如何处理ISO 15 WSS断开问题，并关闭permessage-deflate扩展。\n处理IOS WSS断开问题并关闭 permessage-deflate 背景 在IOS使用WebSocket（WSS）进行通信时，有时会出现连接断开的问题。可能需要关闭permessage-deflate扩展以避免兼容性问题。本文档将详细介绍如何在Nginx和Spring Boot应用中关闭permessage-deflate扩展，以解决WSS断开问题。\n解决方案 1. 关闭 permessage-deflate 扩展 permessage-deflate 是一种WebSocket压缩扩展，用于减少传输的数据量。但在某些情况下，它可能导致兼容性问题，特别是在特定的标准（如ISO 15）中。因此，我们需要关闭此扩展。\n1.1 在 Nginx 中关闭 permessage-deflate 在Nginx配置文件中，可以通过设置proxy_set_header来控制WebSocket扩展。具体步骤如下：\n编辑Nginx配置文件： 通常位于 /etc/nginx/nginx.conf 或 /etc/nginx/conf.d/default.conf。\n添加或修改以下配置： 在 location 块中添加或修改 proxy_set_header 指令，以禁用 permessage-deflate。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 server { listen 443 ssl; server_name example.com; ssl_certificate /path/to/certificate.pem; ssl_certificate_key /path/to/privatekey.pem; location /ws { proxy_pass http://backend_server; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; #重点 proxy_set_header Sec-WebSocket-Extensions \u0026#39;client_max_window_bits=0\u0026#39;; } } 注意：\nSec-WebSocket-Extensions 'client_max_window_bits=0' 表示禁用 permessage-deflate。 如果需要完全禁用所有扩展，可以设置为空字符串：Sec-WebSocket-Extensions ''。 重新加载Nginx配置：\n1 sudo nginx -s reload 1.2 在 Spring Boot 中关闭 permessage-deflate 在Spring Boot应用中，可以通过tomcat系统属性来禁用内置的WebSocket扩展。\n令行参数设置，可以在启动Spring Boot应用时添加以下参数：\n1 java -Dorg.apache.tomcat.websocket.DISABLE_BUILTIN_EXTENSIONS=true -jar your-application.jar ","date":"2025-02-26T10:46:28.54Z","permalink":"https://wlngo.github.io/archives/ios-wss-question/","title":"ios wss 断开问题"},{"content":" 取消ipv6 改为禁用 改ipv6视频 ","date":"2024-06-05T10:06:14.23Z","permalink":"https://wlngo.github.io/archives/openwrtipv6/","title":"openwrt  ipv6"},{"content":"githu地址\n1 2 3 4 5 docker run -d --name chatgpt-next-web -p 3000:3000 --restart=always \\ -e OPENAI_API_KEY=\u0026#34;sk-\u0026#34; \\ -e BASE_URL=\u0026#34;https://openkey.cloud\u0026#34; \\ -e CODE=2411228533 \\ yidadaa/chatgpt-next-web ","date":"2024-05-17T17:53:15.869Z","permalink":"https://wlngo.github.io/archives/chatgpt-next-web%E5%AE%89%E8%A3%85/","title":"chatgpt-next-web 安装"},{"content":"mybatis-plus v3.4.0 fix: @TableName.autoResultMap=true 情况下, 内置的 selectBody 将不会进行 as ,使用了的需要注意!!! feat: 新增 mybatis-plus-boot-starter-test 模块 fix: MetaObjectHandler 重载错误(解决办法是参数位置对调),填充值在泛型上支持字段类型的子类 feat: mybatis up to 3.5.5, mybatis-spring up to 2.0.5 feat: jsqlparser up to 3.2 feat: 新增 MybatisParameterHandler, 废弃 MybatisDefaultParameterHandler feat: 分页插件加入 GBase,ClickHouse,oscar,OceanBase 数据库连接自动识别的支持 feat: Wrapper 新增api not(boolean condition, Consumer consumer) feat: 新增 MybatisPlusInterceptor 解决 多租户和分页 插件一级和二级缓存不正确问题 feat: 新分页插件优化 size\u0026lt;0 时继续拼接 orderBy feat: 新增 IdentifierGenerator 一个实现类 ImadcnIdentifierGenerator fix: chainWrapper#func 强转异常 fix(mybatis-plus-generator.main): 重构生成器数据库类型转换器，修复部分支条，提交选择器测试 fix: 修复复杂情况中动态表名替换产生的问题：正则由空白检测转为单词边界检测 refactor: 重构动态表名解析器，去除正则替换程序，改为按表名位置进行替换 refactor: 将表名解析重构为访问者模式，现在不会对原有 SQL 做改动\nImadcnIdentifierGenerator 用于id生成\n地址 idwork mybatis-plus\n1.引入maven依赖 1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.imadcn.framework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;idworker\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2.添加zookeeper配置 1 mybatis-plus.zookeeper.serverLists=127.0.0.1:2181 3.指定mybatis-plus的id生成器 @Configuration public class IdAutoConfig { @Value(\u0026quot;${mybatis-plus.zookeeper.serverLists}\u0026quot;) private String zkServerLists; @Bean public IdentifierGenerator idGenerator() { return new ImadcnIdentifierGenerator(zkServerLists); } }\n","date":"2024-03-14T18:05:22.447Z","permalink":"https://wlngo.github.io/archives/mybatis-plus-ji-cheng-idworker/","title":"mybatis-plus 集成idworker"},{"content":"安装\n1 curl https://get.acme.sh | sh -s email=my@example.com 卸载\n1 acme.sh --uninstall 设置提供商\n1 acme.sh --set-default-ca --server letsencrypt 1 acme.sh --set-default-ca --server zerossl DNSPod.cn 域名 API 选项要求您首先登录您的帐户以获取 DNSPod API 密钥和 ID。\n1 2 export DP_Id=\u0026#34;\u0026lt;id\u0026gt;\u0026#34; export DP_Key=\u0026#34;\u0026lt;key\u0026gt;\u0026#34; 申请\n1 ./acme.sh --insecure --dnssleep 600 --issue --dns dns_dp -d wlngo.top -d *.wlngo.top 删除\n1 acme.sh --remove -d wlngo.top 部署\n1 2 3 4 ./acme.sh --install-cert -d wlngo.top \\ --key-file /etc/nginx/ssl/wlngo.top.key \\ --fullchain-file /etc/nginx/ssl/wlngo.top_bundle.crt \\ --reloadcmd \u0026#34;sh /root/.acme.sh/reload.sh\u0026#34; reload.sh 脚本\n1 2 3 4 5 6 #!/usr/bin/bash systemctl force-reload nginx cp /etc/nginx/ssl/wlngo.top.key /opt/gitlab/config/ssl/wlngo.top.key cp /etc/nginx/ssl/wlngo.top_bundle.crt /opt/gitlab/config/ssl/ docker exec -it gitlab /bin/bash gitlab-ctl reconfigure 自动更新\n1 acme.sh --upgrade --auto-upgrade 自动更新 关闭\n1 acme.sh --upgrade --auto-upgrade 0 ","date":"2024-03-12T14:28:33.289Z","permalink":"https://wlngo.github.io/archives/acmesh%E8%AF%81%E4%B9%A6%E7%94%B3%E8%AF%B7/","title":"acme.sh  证书申请"},{"content":"https://docs.gitlab.cn/jh/ci/examples/\n","date":"2024-03-07T22:57:26.358Z","permalink":"https://wlngo.github.io/archives/gitlabcicd-mo-ban/","title":"gitlab cicd 模板"},{"content":"同步文件\n1 rsync -avux -e \u0026#39;ssh -p 22\u0026#39; root@192.168.123.181:/opt/* ./ 设置主机名字\n1 hostnamectl set-hostname name 查看更改是否生效。\n1 hostnamectl status centos 修改静态ip\n1 cd /etc/sysconfig/network-scripts \u0026amp;\u0026amp; vim ifcfg-ens19 rockylinux 同步时间\n1 chronyc -a makestep debian系列 同步时间\n1 systemctl restart systemd-timesyncd W269N-WFGWX-YVC9B-4J6C9-T83GX #Windows 10/ Windows 11 KMS 安装激活密钥 #Windows 10/11 Pro：W269N-WFGWX-YVC9B-4J6C9-T83GX #Windows 10/11 Enterprise：NPPR9-FWDCX-D2C8J-H872K-2YT43 #Windows 10/11 Pro for Workstations：NRG8B-VKK3Q-CXVCJ-9G2XF-6Q84J\n","date":"2024-01-20T23:37:14.61Z","permalink":"https://wlngo.github.io/archives/%E6%9D%82%E9%A1%B9/","title":"杂项"},{"content":" 1 docker run -d --name=xunlei -p 2345:2345 -v /opt/xunlei/data:/xunlei/data -v /opt/qbittorrent/downloads:/xunlei/downloads --restart=always --privileged cnk3x/xunlei:latest ","date":"2023-11-09T08:56:08.87Z","permalink":"https://wlngo.github.io/archives/xun-lei-web/","title":"迅雷web"},{"content":"docker 部署集群\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 docker run --name nacos --restart always \\ -e TZ=Asia/Shanghai \\ -e JVM_XMS=512m \\ -e JVM_XMX=512m \\ -e JVM_XMN=256m \\ -e JVM_XMS=64m \\ -e JVM_MMS=160m \\ -e NACOS_SERVER_IP=192.168.123.242 \\ -e NACOS_SERVERS=\u0026#34;192.168.123.221:8848 192.168.123.176:8848 192.168.123.242:8848\u0026#34; \\ -e SPRING_DATASOURCE_PLATFORM=mysql \\ -e MYSQL_SERVICE_HOST=10.0.0.3 \\ -e MYSQL_SERVICE_PORT=4000 \\ -e MYSQL_SERVICE_DB_NAME=nacos \\ -e MYSQL_SERVICE_USER=\u0026#34;root\u0026#34; \\ -e MYSQL_SERVICE_PASSWORD=\u0026#34;密码\u0026#34; \\ -e NACOS_AUTH_IDENTITY_KEY=\u0026#34;nacos\u0026#34; \\ -e NACOS_AUTH_IDENTITY_VALUE=\u0026#34;密码\u0026#34; \\ -e NACOS_AUTH_ENABLE=\u0026#34;true\u0026#34; \\ -e NACOS_AUTH_TOKEN=\u0026#34;CbUgzg/ZXr9j3nDJ/IZvznPk5A5PtkdgHM3m7odHII4=\u0026#34; \\ -p 8848:8848 -p 9848:9848 -p 9849:9849 -p7848:7848 -d \\ nacos/nacos-server:v2.3.0 nacos-syc\n1 2 3 4 docker run --name nacos-sync --restart always -d \\ -e TZ=Asia/Shanghai \\ -p 8083:8083 \\ weiliangning.work:18040/docker/nacos-syc ","date":"2023-10-23T17:43:31.378Z","permalink":"https://wlngo.github.io/archives/nacos/","title":"nacos"},{"content":"etcd 安装\n1 2 3 4 5 6 7 docker run -d --restart always \\ --name etcd -p 2379:2379 -p 2380:2380 \\ -e ALLOW_NONE_AUTHENTICATION=yes \\ -e ETCD_ADVERTISE_CLIENT_URLS=http://192.168.123.185:2379 \\ -e TZ=Asia/Shanghai \\ -v /opt/etcd/data:/bitnami/etcd/data \\ bitnami/etcd:3.5 apisix 安装\n1 2 3 4 5 docker run -d --name apisix --restart always \\ -e TZ=Asia/Shanghai \\ -p 9080:9080 -p 9443:9443 -p 9180:9180 -p 9091:9091 \\ -v /opt/apisix/conf/config.yaml:/usr/local/apisix/conf/config.yaml \\ apache/apisix:3.2.2-debian dashboard 安装\n1 2 3 4 5 6 docker run -d --name apisix-dashboard --restart always \\ -e TZ=Asia/Shanghai \\ -p 9000:9000 \\ -v /opt/apisix-dashboard/config/conf.yaml:/usr/local/apisix-dashboard/conf/conf.yaml \\ -v /opt/apisix-dashboard/logs:/usr/local/apisix-dashboard/logs/ \\ apache/apisix-dashboard ","date":"2023-09-25T17:06:16.494Z","permalink":"https://wlngo.github.io/archives/apisix%E5%AE%89%E8%A3%85/","title":"apisix  安装"},{"content":"命令\n1 2 3 4 5 6 7 8 9 docker run \\ --restart=always \\ -e LANG=en_US.UTF-8 \\ -e LANGUAGE=en_US:en \\ -e LC_ALL=en_US.UTF-8 \\ -e TZ=Asia/Shanghai \\ --name=sftp \\ -v /opt/qbittorrent/downloads:/home/foo/upload \\ -p 44:22 -d atmoz/sftp foo:pass:::upload ","date":"2023-09-01T14:59:32.338Z","permalink":"https://wlngo.github.io/archives/docker%E5%AE%89%E8%A3%85sftp/","title":"docker 安装sftp"},{"content":"wireguard部署\n-p 51820:51820/udp 暴露端口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 docker run -d \\ --name=wireguard \\ --cap-add=NET_ADMIN \\ -e PUID=1000 \\ -e PGID=1000 \\ -e TZ=Asia/Shanghai \\ -e SERVERURL=www.wlngo.top \\ -e SERVERPORT=51820 \\ -e PEERDNS=192.168.123.1 \\ -e INTERNAL_SUBNET=10.13.13.0 \\ -e ALLOWEDIPS=0.0.0.0/0 \\ -e PERSISTENTKEEPALIVE_PEERS=\u0026#34;all\u0026#34; \\ -e LOG_CONFS=true \\ -v /mnt/nvme0n1-4/opt/wireguard/config:/config \\ --sysctl=\u0026#34;net.ipv4.conf.all.src_valid_mark=1\u0026#34; \\ --restart always \\ lscr.io/linuxserver/wireguard:v1.0.20210914-ls31 wireguard-ui 初始化使用 0.5.2版本 0.6.2 无法初始化\n\u0026ndash;network=wireguard\n1 2 3 4 docker run -d --net=host -e \u0026#39;BIND_ADDRESS\u0026#39;=\u0026#39;192.168.123.1:5000\u0026#39; --restart=always --name wireguard-ui \\ -e WGUI_MANAGE_RESTART=true -e WGUI_MANAGE_START=true --cap-add=NET_ADMIN \\ -v /mnt/nvme0n1-4/opt/wireguard-ui/db:/app/db -v /mnt/nvme0n1-4/opt/wireguard/config/wg_confs:/etc/wireguard \\ ngoduykhanh/wireguard-ui:0.6.2 inotifywait 监控文件变化脚本\n1 2 3 4 5 6 7 8 #!/bin/bash dir=/opt/wireguard/config/wg_confs/wg0.conf #指定需要监视的文件夹 log_file=/opt/wireguard/logs/changes.log #指定输出信息的文件，方便后面查看 while inotifywait -r $dir -o $log_file -e modify --timefmt \u0026#39;%y-%m-%d %H:%M\u0026#39; --format \u0026#39;%T %w%f %e\u0026#39; #这里只监视文件的close动作 do docker restart wireguard #执行同步文件的脚本 done ","date":"2023-08-29T10:24:21.388Z","permalink":"https://wlngo.github.io/archives/wireguard/","title":"wireguard"},{"content":"#安装NFS服务器端\n1 sudo apt-get install nfs-kernel-server NFS服务器端配置 (/etc/exports)\n1 2 /opt/nfs 192.168.123.0/24(rw,sync,no_subtree_check,insecure,no_root_squash) /opt/nfs 10.0.0.0/24(rw,sync,no_subtree_check,insecure,no_root_squash) 解释\nrw 读写访问 sync 所有数据在请求时写入共享 No_root_squash 客户机用root访问该共享文件夹时，不映射root用户 insecure NFS通过1024以上的端口发送 (如果客户端必须要 mount -o noresvport 访问，那么就需要 nfs 服务器配置允许非特权端口访问。需要修改 /etc/exports，设置 insecure 选项。) no_subtree_check 不检查父目录权限 #安装NFS客户端\n1 sudo apt-get install nfs-common NFS客户端开机自启 配置目录(/etc/fstab)\n1 2 #nfs 10.0.0.2:/opt/nfs /opt/webserver nfs vers=4,minorversion=0,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,_netdev,noresvport 0 0 参数解释\nvers=4 文件系统版本4 minorversion=0 生成注册句柄 minorVersion 是供应商为其产品定义的版本识别码 通常搭配vers=4使用 rsize 每个READ命令字向服务器读取文件的最大字节数。实际数据小于或等于此值。resize必须是1024倍数的正整数，小于1024时自动设为4096，大于1048576时自动设为1048576。默认时，服务器和客户端进行协商后设置 wsize 每个WRITE命令字向服务器写入文件的最大字节数。实际数据小于或等于此值。resize必须是1024倍数的正整数，小于1024时自动设为4096，大于1048576时自动设为1048576。默认时，服务器和客户端进行协商后设置。 hard 使用硬挂载的方式挂载系统，该值是默认值，重复请求直到NFS服务器回应 timeo=600 — 将NFS 客户端在重试NFS 请求之前用于等待响应的超时值设置为600 分秒（60 秒）。 如果您必须更改超时参数( timeo )，我们建议您使用至少为 150 的值，这相当于15 秒 retrans=2 — 将NFS 客户端在尝试进一步恢复操作之前重试请求的次数设置为2。 noresvport — 告诉NFS 客户端在重新建立网络连接时使用新的传输控制协议(TCP) 源端口。 _netdev它用于指示系统在网络挂载文件系统时等待网络连接建立之后再进行挂载操作 noresvport — 告诉NFS 客户端在重新建立网络连接时使用新的传输控制协议(TCP) 源端口。 这样做有助于确保EFS 文件系统在网络恢复事件后具有不间断的可用性。 _netdev — 如果存在 /etc/fstab ，则防止客户端在启用网络之前尝试装载EFS 文件系统\n(如果客户端必须要 mount -o noresvport 访问，那么就需要 nfs 服务器配置允许非特权端口访问。需要修改 /etc/exports，设置 insecure 选项。） 阿里云nfs挂载参考\n","date":"2023-08-23T22:40:03.3Z","permalink":"https://wlngo.github.io/archives/nfs%E5%AE%89%E8%A3%85/","title":"nfs 安装"},{"content":"keepalived配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 cat \u0026gt; /etc/keepalived/keepalived.conf \u0026lt;\u0026lt; EOF ! Configuration File for keepalived global_defs { router_id LVS_DEVEL enable_script_security script_user root } vrrp_script check_haproxy { script \u0026#34;killall -0 haproxy\u0026#34; interval 3 weight -2 fall 10 rise 2 } vrrp_instance VI_1 { state BACKUP interface ens18 # 虚拟网卡桥接的真实网卡 virtual_router_id 80 # 优先级配置，每台服务器最好都不一样，如100，90，80等，优先级越高越先使用 priority 80 advert_int 1 authentication { auth_type PASS auth_pass 111 } virtual_ipaddress { 192.168.123.200 # 对外提供的虚拟IP } track_script { check_haproxy } } EOF 监控keepalived 1 2 3 4 5 6 7 8 9 10 11 #!/bin/sh errorExit() { echo \u0026#34;*** $*\u0026#34; 1\u0026gt;\u0026amp;2 exit 1 } curl --silent --max-time 2 --insecure http://localhost:6443/ -o /dev/null || errorExit \u0026#34;Error GET http://localhost:6443/\u0026#34; if ip addr | grep -q 192.168.123.200; then curl --silent --max-time 2 --insecure http://192.168.123.200:6443/ -o /dev/null || errorExit \u0026#34;Error GET http://192.168.123.200:6443/\u0026#34; fi haproxy配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #--------------------------------------------------------------------- # kubernetes apiserver frontend which proxys to the backends #--------------------------------------------------------------------- frontend kubernetes-apiserver mode tcp bind *:6444 # 对外提供服务的端口，必须和kubernetes一致 option tcplog default_backend kubernetes-apiserver #后端服务的名称 #--------------------------------------------------------------------- # round robin balancing between the various backends #--------------------------------------------------------------------- backend kubernetes-apiserver mode tcp balance roundrobin server node-master-1 192.168.123.246:6443 check # 后端服务器hostname和IP server node-master-2 192.168.123.213:6443 check # 后端服务器hostname和IP server node-master-3 192.168.123.154:6443 check # 后端服务器hostname和IP https://developer.volcengine.com/articles/7052310062315864101 /etc/crictl.yaml https://zhuanlan.zhihu.com/p/585865389 /etc/containerd/config.toml\n命令 污点和容忍\n1 kubectl get no -o yaml | grep taint -A 5 1 kubectl taint nodes node-master-1 node-role.kubernetes.io/control-plane:NoSchedule 批量删除容器\n1 crictl ps -a | awk \u0026#39;{print $1}\u0026#39; | xargs crictl rm 查看coredns\n1 kubectl get pods --namespace=kube-system -l k8s-app=kube-dns ","date":"2023-08-18T17:31:15.705Z","permalink":"https://wlngo.github.io/archives/k8s-an-zhuang/","title":"k8s 安装"},{"content":"安装脚本\n1 sudo bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/trojan-gfw/trojan-quickstart/master/trojan-quickstart.sh)\u0026#34; ","date":"2023-07-25T21:07:49.97Z","permalink":"https://wlngo.github.io/archives/trojan-an-zhuang/","title":"trojan 安装"},{"content":"tidb 分布式数据库 参考[官网文档 https://docs.pingcap.com/zh/tidb/stable/quick-start-with-tidb/]\n部署 部署pd1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 docker run -d --name pd1 \\ --restart always\\ -e TZ=Asia/Shanghai \\ -v /opt/tidb/node_exporter:/opt/tidb/node_exporter \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/tidb/pd1/data:/data \\ --network=elknetwork \\ pingcap/pd:v7.1.0 \\ --name=\u0026#34;pd1\u0026#34; \\ --data-dir=\u0026#34;/data/pd1\u0026#34; \\ --client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; \\ --advertise-client-urls=\u0026#34;http://pd1:2379\u0026#34; \\ --peer-urls=\u0026#34;http://0.0.0.0:2380\u0026#34; \\ --advertise-peer-urls=\u0026#34;http://pd1:2380\u0026#34; \\ --initial-cluster=\u0026#34;pd1=http://pd1:2380,pd2=http://pd2:2380,pd3=http://pd3:2380\u0026#34; 部署pd2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 docker run -d --name pd2 \\ -p 2379:2379 \\ --restart always \\ -e TZ=Asia/Shanghai \\ -v /opt/tidb/node_exporter:/opt/tidb/node_exporter \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/tidb/pd2/data:/data \\ --network=elknetwork \\ pingcap/pd:v7.1.0 \\ --name=\u0026#34;pd2\u0026#34; \\ --data-dir=\u0026#34;/data/pd2\u0026#34; \\ --client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; \\ --advertise-client-urls=\u0026#34;http://pd2:2379\u0026#34; \\ --peer-urls=\u0026#34;http://0.0.0.0:2380\u0026#34; \\ --advertise-peer-urls=\u0026#34;http://pd2:2380\u0026#34; \\ --initial-cluster=\u0026#34;pd1=http://pd1:2380,pd2=http://pd2:2380,pd3=http://pd3:2380\u0026#34; 部署pd3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 docker run -d --name pd3 \\ --restart always \\ -e TZ=Asia/Shanghai \\ -v /opt/tidb/node_exporter:/opt/tidb/node_exporter \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/tidb/pd3/data:/data \\ --network=elknetwork \\ pingcap/pd:v7.1.0 \\ --name=\u0026#34;pd3\u0026#34; \\ --data-dir=\u0026#34;/data/pd3\u0026#34; \\ --client-urls=\u0026#34;http://0.0.0.0:2379\u0026#34; \\ --advertise-client-urls=\u0026#34;http://pd3:2379\u0026#34; \\ --peer-urls=\u0026#34;http://0.0.0.0:2380\u0026#34; \\ --advertise-peer-urls=\u0026#34;http://pd3:2380\u0026#34; \\ --initial-cluster=\u0026#34;pd1=http://pd1:2380,pd2=http://pd2:2380,pd3=http://pd3:2380\u0026#34; 部署tikv1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 docker run -d --name tikv1 \\ --restart always \\ --ulimit nofile=1000000:1000000 \\ -e TZ=Asia/Shanghai \\ -v /opt/tidb/node_exporter:/opt/tidb/node_exporter \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/tidb/tikv1/data:/data \\ --network=elknetwork \\ pingcap/tikv:v7.1.0 \\ --addr=\u0026#34;0.0.0.0:20160\u0026#34; \\ --advertise-addr=\u0026#34;tikv1:20160\u0026#34; \\ --data-dir=\u0026#34;/data/tikv1\u0026#34; \\ --pd=\u0026#34;pd1:2379,pd2:2379,pd3:2379\u0026#34; \\ --advertise-status-addr=\u0026#34;tikv1:20180\u0026#34; \\ --status-addr=\u0026#34;0.0.0.0:20180\u0026#34; 部署tikv2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 docker run -d --name tikv2 \\ --restart always \\ --ulimit nofile=1000000:1000000 \\ -e TZ=Asia/Shanghai \\ -v /opt/tidb/node_exporter:/opt/tidb/node_exporter \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/tidb/tikv2/data:/data \\ --network=elknetwork \\ pingcap/tikv:v7.1.0 \\ --addr=\u0026#34;0.0.0.0:20160\u0026#34; \\ --advertise-addr=\u0026#34;tikv2:20160\u0026#34; \\ --data-dir=\u0026#34;/data/tikv2\u0026#34; \\ --pd=\u0026#34;pd1:2379,pd2:2379,pd3:2379\u0026#34; \\ --advertise-status-addr=\u0026#34;tikv2:20180\u0026#34; \\ --status-addr=\u0026#34;0.0.0.0:20180\u0026#34; 部署tikv3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 --restart always \\ --ulimit nofile=1000000:1000000 \\ -e TZ=Asia/Shanghai \\ -v /opt/tidb/node_exporter:/opt/tidb/node_exporter \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/tidb/tikv3/data:/data \\ --network=elknetwork \\ pingcap/tikv:v7.1.0 \\ --addr=\u0026#34;0.0.0.0:20160\u0026#34; \\ --advertise-addr=\u0026#34;tikv3:20160\u0026#34; \\ --data-dir=\u0026#34;/data/tikv3\u0026#34; \\ --pd=\u0026#34;pd1:2379,pd2:2379,pd3:2379\u0026#34; \\ --advertise-status-addr=\u0026#34;tikv3:20180\u0026#34; \\ --status-addr=\u0026#34;0.0.0.0:20180\u0026#34; 部署tidb 1 2 3 4 5 6 7 8 9 10 11 12 docker run -d --name tidb \\ --restart always \\ -p 4000:4000 \\ -p 10080:10080 \\ -e TZ=Asia/Shanghai \\ -v /opt/tidb/node_exporter:/opt/tidb/node_exporter \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ --network=elknetwork \\ pingcap/tidb:v7.1.0 \\ --store=tikv \\ --path=\u0026#34;pd1:2379,pd2:2379,pd3:2379\u0026#34; 部署tiflash 1 2 3 4 5 6 7 8 9 docker run --name tiflash \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/tidb/tiflash/data:/data \\ -v /opt/tidb/tiflash/conf/tiflash.toml:/opt/tidb/tiflash/conf/tiflash.toml \\ --restart always -d \\ --network=elknetwork \\ pingcap/tiflash:v7.1.0 --config=/opt/tidb/tiflash/conf/tiflash.toml 部署ng-monitoring 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 docker run --name ng-monitoring \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/tidb/ng-monitoring/data:/data \\ -v /opt/tidb/ng-monitoring/conf/config.toml:/opt/tidb/ng-monitoring/conf/config.toml \\ --restart always -d \\ --network=elknetwork \\ pingcap/ng-monitoring:v7.1.0 --config=/opt/tidb/ng-monitoring/conf/config.toml docker exec tidb sh /opt/tidb/node_exporter/start.sh docker exec pd1 sh /opt/tidb/node_exporter/start.sh docker exec pd2 sh /opt/tidb/node_exporter/start.sh docker exec pd3 sh /opt/tidb/node_exporter/start.sh docker exec tikv1 sh /opt/tidb/node_exporter/start.sh docker exec tikv2 sh /opt/tidb/node_exporter/start.sh docker exec tikv3 sh /opt/tidb/node_exporter/start.sh 内存优化 1 2 docker update --memory 6g --memory-swap -1 tiflash tidb tikv1 tikv2 tikv3 pd1 pd2 pd3 docker update --memory 1g --memory-swap -1 ng-monitoring SELECT @@tidb_server_memory_limit 默认=80% SET GLOBAL tidb_server_memory_limit = \u0026ldquo;4GB\u0026rdquo;; SELECT @@tidb_server_memory_limit_gc_trigger 默认=0.7 select sysdate() 查询日期 ALTER USER \u0026lsquo;root\u0026rsquo;@\u0026rsquo;%\u0026rsquo; IDENTIFIED BY \u0026lsquo;mypass\u0026rsquo;; 修改root密码\nHAProxy 代理tidb 安装\n1 sudo apt install haproxy /etc/haproxy/haproxy.cfg 配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 global # 全局配置。 log 127.0.0.1 local2 # 定义全局的 syslog 服务器，最多可以定义两个。 chroot /var/lib/haproxy # 更改当前目录并为启动进程设置超级用户权限，从而提高安全性。 pidfile /var/run/haproxy.pid # 将 HAProxy 进程的 PID 写入 pidfile。 maxconn 4000 # 每个 HAProxy 进程所接受的最大并发连接数。 user haproxy # 同 UID 参数。 group haproxy # 同 GID 参数，建议使用专用用户组。 nbproc 40 # 在后台运行时创建的进程数。在启动多个进程转发请求时，确保该值足够大，保证 HAProxy 不会成为瓶颈。 daemon # 让 HAProxy 以守护进程的方式工作于后台，等同于命令行参数“-D”的功能。当然，也可以在命令行中用“-db”参数将其禁用。 stats socket /var/lib/haproxy/stats # 统计信息保存位置。 defaults # 默认配置。 log global # 日志继承全局配置段的设置。 retries 2 # 向上游服务器尝试连接的最大次数，超过此值便认为后端服务器不可用。 timeout connect 2s # HAProxy 与后端服务器连接超时时间。如果在同一个局域网内，可设置成较短的时间。 timeout client 30000s # 客户端与 HAProxy 连接后，数据传输完毕，即非活动连接的超时时间。 timeout server 30000s # 服务器端非活动连接的超时时间。 listen admin_stats # frontend 和 backend 的组合体，此监控组的名称可按需进行自定义。 bind 0.0.0.0:8080 # 监听端口。 mode http # 监控运行的模式，此处为 `http` 模式。 option httplog # 开始启用记录 HTTP 请求的日志功能。 maxconn 10 # 最大并发连接数。 stats refresh 30s # 每隔 30 秒自动刷新监控页面。 stats uri /haproxy # 监控页面的 URL。 stats realm HAProxy # 监控页面的提示信息。 stats auth admin:pingcap123 # 监控页面的用户和密码，可设置多个用户名。 stats hide-version # 隐藏监控页面上的 HAProxy 版本信息。 stats admin if TRUE # 手工启用或禁用后端服务器（HAProxy 1.4.9 及之后版本开始支持）。 listen tidb-cluster # 配置 database 负载均衡。 bind 0.0.0.0:3390 # 浮动 IP 和 监听端口。 mode tcp # HAProxy 要使用第 4 层的传输层。 balance leastconn # 连接数最少的服务器优先接收连接。`leastconn` 建议用于长会话服务，例如 LDAP、SQL、TSE 等，而不是短会话协议，如 HTTP。该算法是动态的，对于启动慢的服务器，服务器权重会在运行中作调整。 server tidb-1 10.9.18.229:4000 check inter 2000 rise 2 fall 3 # 检测 4000 端口，检测频率为每 2000 毫秒一次。如果 2 次检测为成功，则认为服务器可用；如果 3 次检测为失败，则认为服务器不可用。 server tidb-2 10.9.39.208:4000 check inter 2000 rise 2 fall 3 server tidb-3 10.9.64.166:4000 check inter 2000 rise 2 fall 3 ","date":"2023-07-24T00:14:34.932Z","permalink":"https://wlngo.github.io/archives/tidbdocker-bu-shu/","title":"tidb docker 部署"},{"content":"1主\n1 2 3 4 5 6 7 8 9 docker run -d --name redis-master-1 --network=elknetwork --restart=always \\ -p 6429:6429 -p 16429:16429 \\ -v /opt/redis-cluster/master-1/log:/var/log/redis/ \\ -v /opt/redis-cluster/master-1/conf:/usr/local/etc/redis/ \\ -v /opt/redis-cluster/master-1/data/:/var/lib/redis/ \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ redis \\ redis-server /usr/local/etc/redis/redis.conf 2主\n1 2 3 4 5 6 7 8 9 docker run -d --name redis-master-2 --network=elknetwork --restart=always \\ -p 6449:6449 -p 16449:16449 \\ -v /opt/redis-cluster/master-2/log:/var/log/redis/ \\ -v /opt/redis-cluster/master-2/conf:/usr/local/etc/redis/ \\ -v /opt/redis-cluster/master-2/data/:/var/lib/redis/ \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ redis \\ redis-server /usr/local/etc/redis/redis.conf 3主\n1 2 3 4 5 6 7 8 9 docker run -d --name redis-master-3 --network=elknetwork --restart=always \\ -p 6469:6469 -p 16469:16469 \\ -v /opt/redis-cluster/master-3/log:/var/log/redis/ \\ -v /opt/redis-cluster/master-3/conf:/usr/local/etc/redis/ \\ -v /opt/redis-cluster/master-3/data/:/var/lib/redis/ \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ redis \\ redis-server /usr/local/etc/redis/redis.conf 从1\n1 2 3 4 5 6 7 8 9 docker run -d --name redis-slave-1 --network=elknetwork --restart=always \\ -p 6439:6439 -p 16439:16439 \\ -v /opt/redis-cluster/slave-1/log:/var/log/redis/ \\ -v /opt/redis-cluster/slave-1/conf:/usr/local/etc/redis/ \\ -v /opt/redis-cluster/slave-1/data/:/var/lib/redis/ \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ redis \\ redis-server /usr/local/etc/redis/redis.conf 从2\n1 2 3 4 5 6 7 8 9 docker run -d --name redis-slave-2 --network=elknetwork --restart=always \\ -p 6459:6459 -p 16459:16459 \\ -v /opt/redis-cluster/slave-2/log:/var/log/redis/ \\ -v /opt/redis-cluster/slave-2/conf:/usr/local/etc/redis/ \\ -v /opt/redis-cluster/slave-2/data/:/var/lib/redis/ \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ redis \\ redis-server /usr/local/etc/redis/redis.conf 从3\n1 2 3 4 5 6 7 8 9 docker run -d --name redis-slave-3 --network=elknetwork --restart=always \\ -p 6479:6479 -p 16479:16479 \\ -v /opt/redis-cluster/slave-3/log:/var/log/redis/ \\ -v /opt/redis-cluster/slave-3/conf:/usr/local/etc/redis/ \\ -v /opt/redis-cluster/slave-3/data/:/var/lib/redis/ \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ redis \\ redis-server /usr/local/etc/redis/redis.conf 默认参数\n1 2 3 4 5 6 7 docker run -d --name redis-cluster --restart=always -p 6379:6379 -p 16379:16379 \\ -e TZ=Asia/Shanghai \\ -v /opt/redis-cluster/log:/var/log/redis/ \\ -v /opt/redis-cluster/conf:/usr/local/etc/redis/ \\ -v /opt/redis-cluster/data/:/var/lib/redis/ \\ -v /etc/localtime:/etc/localtime:ro \\ redis:7.0 redis-server /usr/local/etc/redis/redis.conf 配置文件\n1 2 3 4 5 6 7 8 #docker 启动不开启守护进程 物理机开启 daemonize no #开启集群模式 cluster-enabled yes cluster-announce-ip 192.168.123.210 cluster-announce-port 6379 #集群通讯端口 cluster-announce-bus-port 16379 规划和集群\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 cluster nodes 查看集群信息\tcluster replicate 映射主节点 主 192.168.123.117 6379 192.168.123.196 6379 192.168.123.139 6379 从 192.168.123.221 6379 192.168.123.176 6379 192.168.123.242 6379 建立联系 redis-cli -h 192.168.123.117 -p 6379 -a 密码 cluster replicate 主节点 cluster meet 192.168.123.196 6379 cluster meet 192.168.123.139 6379 cluster meet 192.168.123.221 6379 cluster meet 192.168.123.176 6379 cluster meet 192.168.123.242 6379 映射主节点 redis-cli -h 192.168.123.221 -p 6379 -a 密码 cluster replicate 主节点 redis-cli -h 192.168.123.176 -p 6379 -a 密码 cluster replicate 主节点 redis-cli -h 192.168.123.242 -p 6379 -a 密码 cluster replicate 主节点 主节点分配哈希槽 redis-cli -h 192.168.123.117 -p 6379 -a 密码 cluster addslots {0..5461} redis-cli -h 192.168.123.196 -p 6379 -a 密码 cluster addslots {5462..10922} redis-cli -h 192.168.123.139 -p 6379 -a 密码 cluster addslots {10923..16383} Envoy Proxy 用于代理redis 集群 envoy.yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 static_resources: listeners: - name: redis_listener address: socket_address: address: 0.0.0.0 port_value: 6480 filter_chains: - filters: - name: envoy.filters.network.redis_proxy typed_config: \u0026#34;@type\u0026#34;: type.googleapis.com/envoy.extensions.filters.network.redis_proxy.v3.RedisProxy stat_prefix: egress_redis settings: op_timeout: 5s prefix_routes: catch_all_route: cluster: redis_cluster downstream_auth_passwords: - inline_string: \u0026#34;密码\u0026#34; clusters: - name: redis_cluster cluster_type: name: envoy.clusters.redis typed_config: \u0026#34;@type\u0026#34;: type.googleapis.com/google.protobuf.Struct value: cluster_refresh_rate: 10s cluster_refresh_timeout: 4s connect_timeout: 4s dns_lookup_family: V4_ONLY lb_policy: CLUSTER_PROVIDED load_assignment: cluster_name: redis_cluster endpoints: lb_endpoints: - endpoint: address: socket_address: address: 192.168.123.210 port_value: 6429 - endpoint: address: socket_address: address: 192.168.123.210 port_value: 6439 - endpoint: address: socket_address: address: 192.168.123.210 port_value: 6449 - endpoint: address: socket_address: address: 192.168.123.210 port_value: 6459 - endpoint: address: socket_address: address: 192.168.123.210 port_value: 6469 - endpoint: address: socket_address: address: 192.168.123.210 port_value: 6479 typed_extension_protocol_options: envoy.filters.network.redis_proxy: \u0026#34;@type\u0026#34;: type.googleapis.com/google.protobuf.Struct value: auth_password: inline_string: \u0026#34;密码\u0026#34; admin: access_log_path: \u0026#34;/opt/envoy/log/access.log\u0026#34; address: socket_address: address: 0.0.0.0 port_value: 6490 1 2 3 4 5 6 docker run -d --name envoy --network=elknetwork --restart=always \\ -p 6480:6480 -p 6490:6490 \\ -v /opt/envoy/conf/envoy.yaml:/etc/envoy/envoy.yaml \\ -v /opt/envoy/log:/opt/envoy/log \\ -v /etc/localtime:/etc/localtime \\ envoyproxy/envoy:v1.26-latest -c /etc/envoy/envoy.yaml --service-cluster proxy --log-level info docker run -d \u0026ndash;name twemproxy \u0026ndash;network=elknetwork \u0026ndash;restart=always -p 6480:6480 -v /etc/nutcracker.conf:/opt/twemproxy/conf/nutcracker.conf malexer/twemproxy\n","date":"2023-07-11T09:25:06.912Z","permalink":"https://wlngo.github.io/archives/dockerredis%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%853%E4%B8%BB3%E4%BB%8E/","title":"docker redis 集群安装3主3从"},{"content":"https://logback.qos.ch/manual/appenders.html\n","date":"2023-06-20T09:17:49.343Z","permalink":"https://wlngo.github.io/archives/logbackdoc/","title":"logback doc"},{"content":" 1 2 3 4 5 6 7 docker run \\ -d --name filebrowser \\ -v /opt/qbittorrent/downloads/:/srv \\ -v /opt/filebrowser/config/filebrowser.db:/database/filebrowser.db \\ -v /opt/filebrowser/config/settings.json:/config/settings.json \\ -p 8070:80 \\ filebrowser/filebrowser:s6 ","date":"2023-04-30T19:34:22.488Z","permalink":"https://wlngo.github.io/archives/filebrowser/","title":"filebrowser"},{"content":"docker run -d \u0026ndash;name=qbittorrent -e PUID=1000 -e PGID=1000 -e TZ=Asia/Shangha -e WEBUI_PORT=8060 -p 8060:8060 -p 16881:16881 -v /opt/qbittorrent/config:/config -v /opt/qbittorrent/downloads:/downloads \u0026ndash;restart always linuxserver/qbittorrent\n","date":"2023-04-30T18:57:39.393Z","permalink":"https://wlngo.github.io/archives/qbittorrent-an-zhuang/","title":"qbittorrent 安装"},{"content":"docker hub镜像\n1 docker pull p3terx/aria2-pro 启动命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 docker run -d \\ --name aria2-pro \\ --restart always \\ --log-opt max-size=1m \\ -e PUID=$UID \\ -e PGID=$GID \\ -e UMASK_SET=022 \\ -e RPC_SECRET=2411228533 \\ -e RPC_PORT=6800 \\ -e LISTEN_PORT=6888 \\ --network=elknetwork \\ -v /opt/aria2/server/aria2-config:/config \\ -v /opt/aria2/server/aria2-downloads:/downloads \\ p3terx/aria2-pro ","date":"2023-04-28T17:24:56.601Z","permalink":"https://wlngo.github.io/archives/aria2/","title":"Aria2"},{"content":"spring.security.oauth2.client.registration.gitee.redirect-uri: 文档 旧的模板值\n1 \u0026#39;{baseUrl}/{action}/oauth2/code/{registrationId}\u0026#39; 新的模板值\n1 \u0026#39;{baseUrl}/login/oauth2/code/{registrationId}\u0026#39; Oauth2.0 资料文档 https://www.jetbrains.com/help/youtrack/devportal/OAuth-authorization-in-hub.html https://juejin.cn/post/7151692788071923742#heading-0 客户端模式 scope 多个需要 单个空格 间隔开 https://developer.okta.com/docs/api/openapi/okta-oauth/guides/client-auth/#token-claims-for-client-authentication-with-client-secret-or-private-key-jwt https://cloudentity.com/developers/basics/oauth-client-authentication/client-secret-authentication/#authentication-using-client_secret_basic-method 注册(RegisteredClientRepository) token(OAuth2AuthorizationService) https://docs.spring.io/spring-security/reference/servlet/oauth2/index.html https://spring.io/projects/spring-authorization-server Spring Security 权限决策 （AccessDecisionManager） 一票通过(AffirmativeBased) 一票否决(UnanimousBased) 少数服从多数(ConsensusBased) Spring Security json 登录（spring boot 3 +） https://www.duidaima.com/Group/Topic/JAVA/10494(Spring Security ) jwks https://fullstackladder.dev/blog/2023/01/28/openid-validate-token-with-rs256-and-jwks/\n","date":"2023-04-24T17:56:24.552Z","permalink":"https://wlngo.github.io/archives/oauth20/","title":"oauth2.0"},{"content":" 1 2 3 4 5 6 docker run -d --name=grafana -p 3000:3000 \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /var/opt/grafana/data/:/var/lib/grafana \\ grafana/grafana ","date":"2023-04-16T21:40:08.073Z","permalink":"https://wlngo.github.io/archives/grafana/","title":"grafana"},{"content":" 1 2 3 4 5 6 7 8 9 docker run -d --name sonarqube \\ -p 9000:9000 \\ -e SONAR_JDBC_URL=jdbc:postgresql://www.weiliangning.work:5432/ \\ -e SONAR_JDBC_USERNAME=postgres \\ -e SONAR_JDBC_PASSWORD=... \\ -v /opt/sonarqube/data:/opt/sonarqube/data \\ -v /opt/sonarqube/extensions:/opt/sonarqube/extensions \\ -v /opt/sonarqube/logs:/opt/sonarqube/logs \\ sonarqube:lts ","date":"2023-04-16T18:07:17.297Z","permalink":"https://wlngo.github.io/archives/%E5%AE%89%E8%A3%85sonarqube/","title":"安装  sonarqube"},{"content":"https://hub.docker.com/_/mongo\n1 2 3 4 5 6 7 8 9 docker run --name mongo -d --restart=always \\ -p 27017:27017 \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /var/opt/mongo/data:/data/db \\ -e MONGO_INITDB_ROOT_USERNAME=root \\ -e MONGO_INITDB_ROOT_PASSWORD=secret \\ mongo:6.0-rc ","date":"2023-04-16T17:14:58.455Z","permalink":"https://wlngo.github.io/archives/docker%E5%AE%89%E8%A3%85mongo/","title":"docker 安装mongo"},{"content":"集群需要修改 data 下 myid 分别为1 2 3 (此处是伪集群模式) zookeeper-a 1 2 3 4 5 6 7 8 docker run --name zookeeper-a --restart always -d \\ -v /opt/zookeeper/zookeeper-a/conf/zoo.cfg:/conf/zoo.cfg \\ -v /opt/zookeeper/zookeeper-a/datalog/:/datalog \\ -v /opt/zookeeper/zookeeper-a/data/:/data \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ --network=host \\ zookeeper zookeeper-b 1 2 3 4 5 6 7 8 docker run --name zookeeper-b --restart always -d \\ -v /opt/zookeeper/zookeeper-b/conf/zoo.cfg:/conf/zoo.cfg \\ -v /opt/zookeeper/zookeeper-b/datalog/:/datalog \\ -v /opt/zookeeper/zookeeper-b/data/:/data \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ --network=host \\ zookeeper zookeeper-c 1 2 3 4 5 6 7 8 docker run --name zookeeper-c --restart always -d \\ -v /opt/zookeeper/zookeeper-c/conf/zoo.cfg:/conf/zoo.cfg \\ -v /opt/zookeeper/zookeeper-c/datalog/:/datalog \\ -v /opt/zookeeper/zookeeper-c/data/:/data \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ --network=host \\ zookeeper zookeeper集群 1 2 3 4 5 6 7 docker run --name zookeeper --restart always -d \\ -e TZ=Asia/Shanghai \\ -v /opt/zookeeper/conf/zoo.cfg:/conf/zoo.cfg \\ -v /opt/zookeeper/datalog/:/datalog \\ -v /opt/zookeeper/data/:/data \\ --network=host \\ zookeeper:3.9.1-jre-17 ","date":"2023-04-14T21:11:53.329Z","permalink":"https://wlngo.github.io/archives/zookeeperdocker/","title":"zookeeper docker"},{"content":" 1 2 3 docker run -d --name showdoc --user=root --privileged=true --restart always -p 4999:80 \\ -v /var/opt/showdoc/data:/var/www/html/ \\ star7th/showdoc ","date":"2023-04-14T16:06:25.641Z","permalink":"https://wlngo.github.io/archives/showdocdocker-an-zhuang/","title":"showdoc docker 安装"},{"content":" 1 2 3 4 5 \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;!-- 更新策略默认每天一次--\u0026gt; \u0026lt;updatePolicy\u0026gt;always\u0026lt;/updatePolicy\u0026gt; \u0026lt;/snapshots\u0026gt; ","date":"2023-04-05T21:23:58.909Z","permalink":"https://wlngo.github.io/archives/maven-kuai-zhao-geng-xin-ce-lve-mo-ren-mei-tian-yi-ci/","title":"maven 快照更新策略默认每天一次"},{"content":" 1 2 3 4 5 docker run -d --name gitlab-runner --restart always \\ -v /opt/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner:latest 1 docker exec -it gitlab-runner /bin/bash ","date":"2023-03-29T15:30:49.726Z","permalink":"https://wlngo.github.io/archives/gitlabrunner/","title":"gitlab runner"},{"content":" 1 2 3 4 5 6 docker run -d --name postgres --restart=always --network elknetwork \\ -p 5432:5432 -e POSTGRES_PASSWORD_FILE=/opt/postgres/config/postgres-password \\ -v /var/opt/postgres/data:/var/lib/postgresql/data \\ -v /opt/postgres/config/:/opt/postgres/config/ \\ -v /etc/timezone:/etc/timezone:ro -v /etc/localtime:/etc/localtime:ro \\ weiliangning.work:18040/docker/postgres:15.2 ","date":"2023-03-28T20:21:30.09Z","permalink":"https://wlngo.github.io/archives/docker-an-zhuang-postgresql/","title":"docker 安装postgresql"},{"content":" 1 2 3 4 5 6 7 8 def jobName = \u0026#34;tes\u0026#34; //删除的项目名称 def maxNumber = 200 // 保留的最小编号，意味着小于该编号的构建都将被删除 Jenkins.instance.getItemByFullName(jobName).builds.findAll { it.number \u0026lt;= maxNumber }.each { it.delete() } ","date":"2023-03-27T22:18:02.58Z","permalink":"https://wlngo.github.io/archives/jenkins-shan-chu-li-shi-gou-jian/","title":"jenkins 删除历史构建"},{"content":"https://cloud.tencent.com/developer/article/2129798 修改端口必须重启\n","date":"2023-03-24T01:16:37.613Z","permalink":"https://wlngo.github.io/archives/xrdp-jiao-cheng/","title":"xrdp 教程"},{"content":"https://www.cnblogs.com/niaucz/p/14817775.html\n","date":"2023-03-23T23:37:30.248Z","permalink":"https://wlngo.github.io/archives/shi-yong-tls-bao-hu-docker-yuan-cheng-duan-kou/","title":"使用TLS保护Docker远程端口"},{"content":"nginx 设置\n1 2 auth_basic \u0026#34;请输入用户名和密码\u0026#34;; auth_basic_user_file /etc/nginx/auth/htpasswd; sudo sh -c \u0026ldquo;echo -n \u0026lsquo;账号:\u0026rsquo; \u0026raquo; htpasswd\u0026rdquo; sudo sh -c \u0026ldquo;openssl passwd -apr1 \u0026raquo; htpasswd\u0026rdquo; 请输入密码\n","date":"2023-03-17T17:17:38.837Z","permalink":"https://wlngo.github.io/archives/nginx-jian-dan-she-zhi-zhang-hao-mi-ma/","title":"nginx 简单设置账号密码"},{"content":"运行自建镜像 1 docker run -d --name arthas-tunnel-server --restart always -p 8580:8080 -p 7777:7777 weiliangning.work:18040/docker/arthas-tunnel-server java agent参数 -javaagent:/opt/arthas/arthas-agent.jar -Darthas.tunnelServer=ws://www.weiliangning.work:7777/ws -Darthas.appName=appname\ndocker 容器参数 \u0026ndash;cap-add=SYS_ADMIN 必须给容器根路径权限 否则无法生产cpu 火焰图 profiler start\narthas 获取spring bean 思路参考 https://github.com/alibaba/arthas/issues/482\n方法一 有dubbo\n1 ognl \u0026#39;#context=@com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory@contexts.iterator.next, #context.getBean(\u0026#34;bean名字\u0026#34;)\u0026#39; 方法二 有hutool\n查看工具类的 classload\n1 sc -d cn.hutool.extra.spring.SpringUtil 使用ognl 执行静态方法\n1 ognl -c 685f4c2e \u0026#39;@cn.hutool.extra.spring.SpringUtil@getBean(\u0026#34;bean名字\u0026#34;)\u0026#39; ","date":"2023-03-17T14:40:29.515Z","permalink":"https://wlngo.github.io/archives/arthasjava-xian-shang-jian-kong-zhen-duan/","title":"arthas java 线上监控诊断"},{"content":"官方配置日志格式\n1 \u0026lt;property name=\u0026#34;CONSOLE_LOG_PATTERN\u0026#34; value=\u0026#34;${CONSOLE_LOG_PATTERN:-%clr(%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot/src/main/resources/org/springframework/boot/logging/logback/defaults.xml\n正常模板 适用于spring boot 2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- 日志级别从低到高分为TRACE \u0026lt; DEBUG \u0026lt; INFO \u0026lt; WARN \u0026lt; ERROR \u0026lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --\u0026gt; \u0026lt;!-- scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true --\u0026gt; \u0026lt;!-- scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 --\u0026gt; \u0026lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --\u0026gt; \u0026lt;configuration debug=\u0026#34;false\u0026#34; scan=\u0026#34;true\u0026#34; scanPeriod=\u0026#34;1000 seconds\u0026#34;\u0026gt; \u0026lt;contextName\u0026gt;logback\u0026lt;/contextName\u0026gt; \u0026lt;!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义变量后，可以使“${}”来使用变量。 --\u0026gt; \u0026lt;property name=\u0026#34;log.path\u0026#34; value=\u0026#34;./logs\u0026#34;/\u0026gt; \u0026lt;springProperty scope=\u0026#34;context\u0026#34; name=\u0026#34;spring.application.name\u0026#34; source=\u0026#34;spring.application.name\u0026#34; defaultValue=\u0026#34;app\u0026#34;/\u0026gt; \u0026lt;!-- 彩色日志 --\u0026gt; \u0026lt;!-- 彩色日志依赖的渲染类 --\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;clr\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.ColorConverter\u0026#34;/\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;wex\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\u0026#34;/\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;wEx\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_PATTERN\u0026#34; value=\u0026#34;${CONSOLE_LOG_PATTERN:-%clr(%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}}){faint} %clr([%X{tid}]){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_CHARSET\u0026#34; value=\u0026#34;${CONSOLE_LOG_CHARSET:-${file.encoding:-UTF-8}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_THRESHOLD\u0026#34; value=\u0026#34;${CONSOLE_LOG_THRESHOLD:-TRACE}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_PATTERN\u0026#34; value=\u0026#34;${FILE_LOG_PATTERN:-%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}} [%X{tid}] ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } --- [%t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_CHARSET\u0026#34; value=\u0026#34;${FILE_LOG_CHARSET:-${file.encoding:-UTF-8}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_THRESHOLD\u0026#34; value=\u0026#34;${FILE_LOG_THRESHOLD:-TRACE}\u0026#34;/\u0026gt; \u0026lt;appender name=\u0026#34;CONSOLE\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.classic.encoder.PatternLayoutEncoder\u0026#34;\u0026gt; \u0026lt;charset\u0026gt;${CONSOLE_LOG_CHARSET}\u0026lt;/charset\u0026gt; \u0026lt;Pattern\u0026gt;${CONSOLE_LOG_PATTERN}\u0026lt;/Pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;LOG_FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;!-- 正在记录的日志文件的路径及文件名 --\u0026gt; \u0026lt;file\u0026gt;${log.path}/${spring.application.name}.log\u0026lt;/file\u0026gt; \u0026lt;!--日志文件输出格式--\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.core.encoder.LayoutWrappingEncoder\u0026#34;\u0026gt; \u0026lt;charset\u0026gt;${FILE_LOG_CHARSET}\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;layout class=\u0026#34;ch.qos.logback.classic.PatternLayout\u0026#34;\u0026gt; \u0026lt;pattern\u0026gt;${FILE_LOG_PATTERN}\u0026lt;/pattern\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;!-- 每天日志归档路径以及格式 --\u0026gt; \u0026lt;fileNamePattern\u0026gt;${log.path}/${spring.application.name}-%d{yyyy-MM-dd}.%i.log.zip\u0026lt;/fileNamePattern\u0026gt; \u0026lt;timeBasedFileNamingAndTriggeringPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\u0026#34;\u0026gt; \u0026lt;maxFileSize\u0026gt;100MB\u0026lt;/maxFileSize\u0026gt; \u0026lt;/timeBasedFileNamingAndTriggeringPolicy\u0026gt; \u0026lt;!--日志文件保留天数--\u0026gt; \u0026lt;maxHistory\u0026gt;365\u0026lt;/maxHistory\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --\u0026gt; \u0026lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --\u0026gt; \u0026lt;!-- 添加附加的appender,最多只能添加一个 --\u0026gt; \u0026lt;appender name=\u0026#34;LOG_ASYNC\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;discardingThreshold\u0026gt;0\u0026lt;/discardingThreshold\u0026gt; \u0026lt;queueSize\u0026gt;256\u0026lt;/queueSize\u0026gt; \u0026lt;includeCallerData\u0026gt;true\u0026lt;/includeCallerData\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_FILE\u0026#34;/\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- additivity是否传递--\u0026gt; \u0026lt;!-- mybatis自动生成文件日志 --\u0026gt; \u0026lt;logger name=\u0026#34;com.baomidou.mybatisplus.generator\u0026#34; level=\u0026#34;debug\u0026#34; additivity=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;logger name=\u0026#34;top.wei.yhproprietaryinteresth5pre\u0026#34; level=\u0026#34;info\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;!-- 指定输出的appender --\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; skywalking模板 适用于spring boot 2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- 日志级别从低到高分为TRACE \u0026lt; DEBUG \u0026lt; INFO \u0026lt; WARN \u0026lt; ERROR \u0026lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --\u0026gt; \u0026lt;!-- scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true --\u0026gt; \u0026lt;!-- scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 --\u0026gt; \u0026lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --\u0026gt; \u0026lt;configuration debug=\u0026#34;false\u0026#34; scan=\u0026#34;true\u0026#34; scanPeriod=\u0026#34;1000 seconds\u0026#34;\u0026gt; \u0026lt;contextName\u0026gt;logback\u0026lt;/contextName\u0026gt; \u0026lt;!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义变量后，可以使“${}”来使用变量。 --\u0026gt; \u0026lt;property name=\u0026#34;log.path\u0026#34; value=\u0026#34;./logs\u0026#34;/\u0026gt; \u0026lt;springProperty scope=\u0026#34;context\u0026#34; name=\u0026#34;spring.application.name\u0026#34; source=\u0026#34;spring.application.name\u0026#34; defaultValue=\u0026#34;app\u0026#34;/\u0026gt; \u0026lt;!-- 彩色日志 --\u0026gt; \u0026lt;!-- 彩色日志依赖的渲染类 --\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;clr\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.ColorConverter\u0026#34;/\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;wex\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\u0026#34;/\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;wEx\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_PATTERN\u0026#34; value=\u0026#34;${CONSOLE_LOG_PATTERN:-%clr(%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}}){faint} %clr([%X{tid}]){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_CHARSET\u0026#34; value=\u0026#34;${CONSOLE_LOG_CHARSET:-${file.encoding:-UTF-8}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_THRESHOLD\u0026#34; value=\u0026#34;${CONSOLE_LOG_THRESHOLD:-TRACE}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_PATTERN\u0026#34; value=\u0026#34;${FILE_LOG_PATTERN:-%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}} [%X{tid}] ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } --- [%t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_CHARSET\u0026#34; value=\u0026#34;${FILE_LOG_CHARSET:-${file.encoding:-UTF-8}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_THRESHOLD\u0026#34; value=\u0026#34;${FILE_LOG_THRESHOLD:-TRACE}\u0026#34;/\u0026gt; \u0026lt;appender name=\u0026#34;CONSOLE\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.core.encoder.LayoutWrappingEncoder\u0026#34;\u0026gt; \u0026lt;charset\u0026gt;${CONSOLE_LOG_CHARSET}\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;!-- mdc接入skywalking--\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.skywalking.apm.toolkit.log.logback.v1.x.mdc.TraceIdMDCPatternLogbackLayout\u0026#34;\u0026gt; \u0026lt;Pattern\u0026gt;${CONSOLE_LOG_PATTERN}\u0026lt;/Pattern\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;LOG_FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;!-- 正在记录的日志文件的路径及文件名 --\u0026gt; \u0026lt;file\u0026gt;${log.path}/${spring.application.name}.log\u0026lt;/file\u0026gt; \u0026lt;!--日志文件输出格式--\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.core.encoder.LayoutWrappingEncoder\u0026#34;\u0026gt; \u0026lt;charset\u0026gt;${FILE_LOG_CHARSET}\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.skywalking.apm.toolkit.log.logback.v1.x.mdc.TraceIdMDCPatternLogbackLayout\u0026#34;\u0026gt; \u0026lt;pattern\u0026gt;${FILE_LOG_PATTERN}\u0026lt;/pattern\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;!-- 每天日志归档路径以及格式 --\u0026gt; \u0026lt;fileNamePattern\u0026gt;${log.path}/${spring.application.name}-%d{yyyy-MM-dd}.%i.log.zip\u0026lt;/fileNamePattern\u0026gt; \u0026lt;timeBasedFileNamingAndTriggeringPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\u0026#34;\u0026gt; \u0026lt;maxFileSize\u0026gt;100MB\u0026lt;/maxFileSize\u0026gt; \u0026lt;/timeBasedFileNamingAndTriggeringPolicy\u0026gt; \u0026lt;!--日志文件保留天数--\u0026gt; \u0026lt;maxHistory\u0026gt;365\u0026lt;/maxHistory\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;!-- 此日志文件只记录info级别的 此配置不适用skywalking 因为onMatch onMismatch 两个字段--\u0026gt; \u0026lt;!-- \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.LevelFilter\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;level\u0026gt;info\u0026lt;/level\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;onMatch\u0026gt;ACCEPT\u0026lt;/onMatch\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;onMismatch\u0026gt;DENY\u0026lt;/onMismatch\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/filter\u0026gt;--\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --\u0026gt; \u0026lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --\u0026gt; \u0026lt;!-- 添加附加的appender,最多只能添加一个 --\u0026gt; \u0026lt;appender name=\u0026#34;LOG_ASYNC\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;discardingThreshold\u0026gt;0\u0026lt;/discardingThreshold\u0026gt; \u0026lt;queueSize\u0026gt;256\u0026lt;/queueSize\u0026gt; \u0026lt;includeCallerData\u0026gt;true\u0026lt;/includeCallerData\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_FILE\u0026#34;/\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- skyWalking日志采集 --\u0026gt; \u0026lt;appender name=\u0026#34;APM_LOG\u0026#34; class=\u0026#34;org.apache.skywalking.apm.toolkit.log.logback.v1.x.log.GRPCLogClientAppender\u0026#34;\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.core.encoder.LayoutWrappingEncoder\u0026#34;\u0026gt; \u0026lt;charset\u0026gt;${FILE_LOG_CHARSET}\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;!-- mdc接入skywalking--\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.skywalking.apm.toolkit.log.logback.v1.x.mdc.TraceIdMDCPatternLogbackLayout\u0026#34;\u0026gt; \u0026lt;Pattern\u0026gt;${FILE_LOG_PATTERN}\u0026lt;/Pattern\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;!-- 此日志文件只记录info级别的 此配置不适用skywalking 因为onMatch onMismatch 两个字段--\u0026gt; \u0026lt;!-- \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.LevelFilter\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;level\u0026gt;info\u0026lt;/level\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;onMatch\u0026gt;ACCEPT\u0026lt;/onMatch\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;onMismatch\u0026gt;DENY\u0026lt;/onMismatch\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/filter\u0026gt;--\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- additivity是否传递--\u0026gt; \u0026lt;!-- mybatis自动生成文件日志 --\u0026gt; \u0026lt;logger name=\u0026#34;com.baomidou.mybatisplus.generator\u0026#34; level=\u0026#34;debug\u0026#34; additivity=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;logger name=\u0026#34;top.wei\u0026#34; level=\u0026#34;info\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;!-- 指定输出的appender --\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;APM_LOG\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;APM_LOG\u0026#34;/\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 正常模板 适用于spring boot 3\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- 日志级别从低到高分为TRACE \u0026lt; DEBUG \u0026lt; INFO \u0026lt; WARN \u0026lt; ERROR \u0026lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --\u0026gt; \u0026lt;!-- scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true --\u0026gt; \u0026lt;!-- scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 --\u0026gt; \u0026lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --\u0026gt; \u0026lt;configuration debug=\u0026#34;false\u0026#34; scan=\u0026#34;true\u0026#34; scanPeriod=\u0026#34;1000 seconds\u0026#34;\u0026gt; \u0026lt;contextName\u0026gt;logback\u0026lt;/contextName\u0026gt; \u0026lt;!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义变量后，可以使“${}”来使用变量。 --\u0026gt; \u0026lt;property name=\u0026#34;log.path\u0026#34; value=\u0026#34;./logs\u0026#34;/\u0026gt; \u0026lt;springProperty scope=\u0026#34;context\u0026#34; name=\u0026#34;spring.application.name\u0026#34; source=\u0026#34;spring.application.name\u0026#34; defaultValue=\u0026#34;app\u0026#34;/\u0026gt; \u0026lt;!-- 彩色日志 --\u0026gt; \u0026lt;!-- 彩色日志依赖的渲染类 --\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;clr\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.ColorConverter\u0026#34;/\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;wex\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\u0026#34;/\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;wEx\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_PATTERN\u0026#34; value=\u0026#34;${CONSOLE_LOG_PATTERN:-%clr(%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}}){faint} %clr([%X{tid}]){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_CHARSET\u0026#34; value=\u0026#34;${CONSOLE_LOG_CHARSET:-${file.encoding:-UTF-8}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_THRESHOLD\u0026#34; value=\u0026#34;${CONSOLE_LOG_THRESHOLD:-TRACE}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_PATTERN\u0026#34; value=\u0026#34;${FILE_LOG_PATTERN:-%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}} [%X{tid}] ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } --- [%t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_CHARSET\u0026#34; value=\u0026#34;${FILE_LOG_CHARSET:-${file.encoding:-UTF-8}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_THRESHOLD\u0026#34; value=\u0026#34;${FILE_LOG_THRESHOLD:-TRACE}\u0026#34;/\u0026gt; \u0026lt;appender name=\u0026#34;CONSOLE\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.classic.encoder.PatternLayoutEncoder\u0026#34;\u0026gt; \u0026lt;charset\u0026gt;${CONSOLE_LOG_CHARSET}\u0026lt;/charset\u0026gt; \u0026lt;Pattern\u0026gt;${CONSOLE_LOG_PATTERN}\u0026lt;/Pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;LOG_FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;!-- 正在记录的日志文件的路径及文件名 --\u0026gt; \u0026lt;file\u0026gt;${log.path}/${spring.application.name}.log\u0026lt;/file\u0026gt; \u0026lt;!--日志文件输出格式--\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.core.encoder.LayoutWrappingEncoder\u0026#34;\u0026gt; \u0026lt;charset\u0026gt;${FILE_LOG_CHARSET}\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.classic.encoder.PatternLayoutEncoder\u0026#34;\u0026gt; \u0026lt;pattern\u0026gt;${FILE_LOG_PATTERN}\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;${log.path}/${spring.application.name}-%d{yyyy-MM-dd}.%i.zip\u0026lt;/fileNamePattern\u0026gt; \u0026lt;maxFileSize\u0026gt;100mb\u0026lt;/maxFileSize\u0026gt; \u0026lt;!-- 默认情况下，maxHistory设置为零，即默认情况下不删除存档--\u0026gt; \u0026lt;maxHistory\u0026gt;0\u0026lt;/maxHistory\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --\u0026gt; \u0026lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --\u0026gt; \u0026lt;!-- 添加附加的appender,最多只能添加一个 --\u0026gt; \u0026lt;appender name=\u0026#34;LOG_ASYNC\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;discardingThreshold\u0026gt;0\u0026lt;/discardingThreshold\u0026gt; \u0026lt;queueSize\u0026gt;256\u0026lt;/queueSize\u0026gt; \u0026lt;includeCallerData\u0026gt;true\u0026lt;/includeCallerData\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_FILE\u0026#34;/\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- additivity是否传递--\u0026gt; \u0026lt;logger name=\u0026#34;top.wei.oauth2server\u0026#34; level=\u0026#34;info\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;!-- 指定输出的appender --\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;logger name=\u0026#34;org.springframework.security\u0026#34; level=\u0026#34;trace\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;!-- 指定输出的appender --\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;!-- sql日志--\u0026gt; \u0026lt;logger name=\u0026#34;top.wei.oauth2server.mapper\u0026#34; level=\u0026#34;debug\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;!-- 指定输出的appender --\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; skywalking模板 适用于spring boot 3\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- 日志级别从低到高分为TRACE \u0026lt; DEBUG \u0026lt; INFO \u0026lt; WARN \u0026lt; ERROR \u0026lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --\u0026gt; \u0026lt;!-- scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true --\u0026gt; \u0026lt;!-- scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 --\u0026gt; \u0026lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --\u0026gt; \u0026lt;configuration debug=\u0026#34;false\u0026#34; scan=\u0026#34;true\u0026#34; scanPeriod=\u0026#34;1000 seconds\u0026#34;\u0026gt; \u0026lt;contextName\u0026gt;logback\u0026lt;/contextName\u0026gt; \u0026lt;!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义变量后，可以使“${}”来使用变量。 --\u0026gt; \u0026lt;property name=\u0026#34;log.path\u0026#34; value=\u0026#34;./logs\u0026#34;/\u0026gt; \u0026lt;springProperty scope=\u0026#34;context\u0026#34; name=\u0026#34;spring.application.name\u0026#34; source=\u0026#34;spring.application.name\u0026#34; defaultValue=\u0026#34;app\u0026#34;/\u0026gt; \u0026lt;!-- 彩色日志 --\u0026gt; \u0026lt;!-- 彩色日志依赖的渲染类 --\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;clr\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.ColorConverter\u0026#34;/\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;wex\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\u0026#34;/\u0026gt; \u0026lt;conversionRule conversionWord=\u0026#34;wEx\u0026#34; converterClass=\u0026#34;org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_PATTERN\u0026#34; value=\u0026#34;${CONSOLE_LOG_PATTERN:-%clr(%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}}){faint} %clr([%X{tid}]){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_CHARSET\u0026#34; value=\u0026#34;${CONSOLE_LOG_CHARSET:-${file.encoding:-UTF-8}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;CONSOLE_LOG_THRESHOLD\u0026#34; value=\u0026#34;${CONSOLE_LOG_THRESHOLD:-TRACE}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_PATTERN\u0026#34; value=\u0026#34;${FILE_LOG_PATTERN:-%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}} [%X{tid}] ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } --- [%t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_CHARSET\u0026#34; value=\u0026#34;${FILE_LOG_CHARSET:-${file.encoding:-UTF-8}}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;FILE_LOG_THRESHOLD\u0026#34; value=\u0026#34;${FILE_LOG_THRESHOLD:-TRACE}\u0026#34;/\u0026gt; \u0026lt;appender name=\u0026#34;CONSOLE\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.core.encoder.LayoutWrappingEncoder\u0026#34;\u0026gt; \u0026lt;charset\u0026gt;${CONSOLE_LOG_CHARSET}\u0026lt;/charset\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.skywalking.apm.toolkit.log.logback.v1.x.mdc.TraceIdMDCPatternLogbackLayout\u0026#34;\u0026gt; \u0026lt;Pattern\u0026gt;${CONSOLE_LOG_PATTERN}\u0026lt;/Pattern\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;LOG_FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;!-- 正在记录的日志文件的路径及文件名 --\u0026gt; \u0026lt;file\u0026gt;${log.path}/${spring.application.name}.log\u0026lt;/file\u0026gt; \u0026lt;!--日志文件输出格式--\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.core.encoder.LayoutWrappingEncoder\u0026#34;\u0026gt; \u0026lt;charset\u0026gt;${FILE_LOG_CHARSET}\u0026lt;/charset\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.skywalking.apm.toolkit.log.logback.v1.x.mdc.TraceIdMDCPatternLogbackLayout\u0026#34;\u0026gt; \u0026lt;pattern\u0026gt;${FILE_LOG_PATTERN}\u0026lt;/pattern\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;${log.path}/${spring.application.name}-%d{yyyy-MM-dd}.%i.zip\u0026lt;/fileNamePattern\u0026gt; \u0026lt;maxFileSize\u0026gt;100mb\u0026lt;/maxFileSize\u0026gt; \u0026lt;!-- 默认情况下，maxHistory设置为零，即默认情况下不删除存档--\u0026gt; \u0026lt;maxHistory\u0026gt;0\u0026lt;/maxHistory\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --\u0026gt; \u0026lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --\u0026gt; \u0026lt;!-- 添加附加的appender,最多只能添加一个 --\u0026gt; \u0026lt;appender name=\u0026#34;LOG_ASYNC\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;discardingThreshold\u0026gt;0\u0026lt;/discardingThreshold\u0026gt; \u0026lt;queueSize\u0026gt;256\u0026lt;/queueSize\u0026gt; \u0026lt;includeCallerData\u0026gt;true\u0026lt;/includeCallerData\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_FILE\u0026#34;/\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- skyWalking日志采集 --\u0026gt; \u0026lt;appender name=\u0026#34;APM_LOG\u0026#34; class=\u0026#34;org.apache.skywalking.apm.toolkit.log.logback.v1.x.log.GRPCLogClientAppender\u0026#34;\u0026gt; \u0026lt;encoder class=\u0026#34;ch.qos.logback.core.encoder.LayoutWrappingEncoder\u0026#34;\u0026gt; \u0026lt;charset\u0026gt;${FILE_LOG_CHARSET}\u0026lt;/charset\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.skywalking.apm.toolkit.log.logback.v1.x.mdc.TraceIdMDCPatternLogbackLayout\u0026#34;\u0026gt; \u0026lt;Pattern\u0026gt;${FILE_LOG_PATTERN}\u0026lt;/Pattern\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;!-- mdc接入skywalking--\u0026gt; \u0026lt;!-- 此日志文件只记录info级别的 此配置不适用skywalking 因为onMatch onMismatch 两个字段--\u0026gt; \u0026lt;!-- \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.LevelFilter\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;level\u0026gt;info\u0026lt;/level\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;onMatch\u0026gt;ACCEPT\u0026lt;/onMatch\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;onMismatch\u0026gt;DENY\u0026lt;/onMismatch\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/filter\u0026gt;--\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- additivity是否传递--\u0026gt; \u0026lt;logger name=\u0026#34;top.wei\u0026#34; level=\u0026#34;info\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;!-- 指定输出的appender --\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;APM_LOG\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; sql日志\u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;logger name=\u0026#34;top.wei.oauth2server.mapper\u0026#34; level=\u0026#34;debug\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt;--\u0026gt; \u0026lt;!-- \u0026amp;lt;!\u0026amp;ndash; 指定输出的appender \u0026amp;ndash;\u0026amp;gt;--\u0026gt; \u0026lt;!-- \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;appender-ref ref=\u0026#34;APM_LOG\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;/logger\u0026gt;--\u0026gt; \u0026lt;root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;LOG_ASYNC\u0026#34;/\u0026gt; \u0026lt;appender-ref ref=\u0026#34;APM_LOG\u0026#34;/\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; ","date":"2023-03-15T15:46:24.022Z","permalink":"https://wlngo.github.io/archives/springboot-de-logbackxml/","title":"Spring boot 的logback.xml"},{"content":"oap 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 docker run --name oap --restart always -d \\ -e SW_STORAGE=elasticsearch \\ -e SW_STORAGE_ES_CLUSTER_NODES=10.0.0.2:9200 \\ -e SW_ES_USER=elastic -e SW_ES_PASSWORD=密码 \\ -e SW_CORE_GRPC_SSL_ENABLED=true \\ -e SW_CORE_GRPC_SSL_KEY_PATH=/skywalking/config/tls/server.pem \\ -e SW_CORE_GRPC_SSL_CERT_CHAIN_PATH=/skywalking/config/tls/server.crt \\ -e SW_CORE_GRPC_SSL_TRUSTED_CA_PATH=/skywalking/config/tls/ca.crt \\ -e JAVA_OPTS=\u0026#34;-Xms2048m -Xmx2048m\u0026#34; \\ -v /opt/oap/tls/:/skywalking/config/tls/ \\ -p 11800:11800 -p 12800:12800 \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ apache/skywalking-oap-server:9.7.0-java17 agent.instance_uuid\nui 1 2 3 4 5 6 7 docker run --name oap-ui --restart always -d \\ -p 8380:8080 \\ -e SW_OAP_ADDRESS=http://10.0.0.2:12800 \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ apache/skywalking-ui:9.7.0-java17 ","date":"2023-03-14T10:37:04.567Z","permalink":"https://wlngo.github.io/archives/skywalking9%E5%AE%89%E8%A3%85/","title":"SkyWalking 9 安装"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 mkdir -p $JFROG_HOME/artifactory-jcr mkdir -p $JFROG_HOME/artifactory-oss mkdir -p $JFROG_HOME/artifactory-oss/var/etc/ cd $JFROG_HOME/artifactory-oss/var/etc/ touch ./system.yaml chown -R 1030:1030 $JFROG_HOME/artifactory-oss/var mkdir -p $JFROG_HOME/artifactory-jcr/var/etc/ cd $JFROG_HOME/artifactory-jcr/var/etc/ touch ./system.yaml chown -R 1030:1030 $JFROG_HOME/artifactory-jcr/var docker run --restart=always --name artifactory-oss -v $JFROG_HOME/artifactory-oss/var/:/var/opt/jfrog/artifactory -d -p 8010:8081 -p 8020:8082 releases-docker.jfrog.io/jfrog/artifactory-oss:7.49.10 docker run --restart=always --name artifactory-jcr -v $JFROG_HOME/artifactory-jcr/var/:/var/opt/jfrog/artifactory -d -p 8030:8081 -p 8040:8082 releases-docker.jfrog.io/jfrog/artifactory-jcr:7.49.10 ","date":"2023-03-14T10:01:17.05Z","permalink":"https://wlngo.github.io/archives/jfrog-de-oss-he-jrc-an-zhuang/","title":"jfrog的oss和JRC安装"},{"content":" 1 redis-cli -c -p 6379 -a 密码-x set mini-file-http-serve-noMatchRegex \u0026lt; noMatchRegex.txt ","date":"2023-02-28T10:58:23.707Z","permalink":"https://wlngo.github.io/archives/redisvalue-xie-ru-wen-jian/","title":"redis value 写入文件"},{"content":"查看当前身份认证\n1 getAcl / Digest 是最常用的权限控制模式，也更符合我们对于权限控制的认识，其类似于 username:password 形式的权限标识来进行权限配置，便于区分不同应用来进行权限控制。\n当我们通过 username:password 形式配置了权限标识。这里的密码是密文，ZooKeeper 会对其先后进行两次编码处理，分别是SHA-1算法加密和BASE64编码，在 SHELL 中可以通过以下命令计算：\n1 echo -n\u0026lt;user\u0026gt;:\u0026lt;password\u0026gt; | openssl dgst -binary -sha1 | openssl base64 例子：\n1 setAcl /test/digest-node-1 digest:user-1:1g4T1B5w+se9ntA6Ckp90uPaJ30=:crdwa ","date":"2023-02-27T11:24:41.165Z","permalink":"https://wlngo.github.io/archives/zookeeper-quan-xian-pei-zhi/","title":"zookeeper 权限配置"},{"content":" 1 docker update --memory 1g --memory-swap -1 jenkins ","date":"2023-02-27T09:37:02.54Z","permalink":"https://wlngo.github.io/archives/docker-xian-zhi-nei-cun/","title":"docker 限制内存"},{"content":"保存数据\n1 sync cache释放： To free pagecache:\n1 echo 1 \u0026gt; /proc/sys/vm/drop_caches ","date":"2023-02-18T18:53:02.053Z","permalink":"https://wlngo.github.io/archives/qing-li-xi-tong-huan-cun/","title":"清理系统缓存"},{"content":"启动 1 2 3 4 5 6 7 8 9 10 11 12 13 14 docker run -d -p 9000:9000 -p 9050:9050 \\ --name minio --restart=always \\ -e \u0026#34;MINIO_SERVER_URL=https://wlngo.top:9000\u0026#34; \\ -e \u0026#34;MINIO_ROOT_USER=账号\u0026#34; \\ -e \u0026#34;MINIO_ROOT_PASSWORD=密码\u0026#34; \\ -e \u0026#34;MINIO_BROWSER_REDIRECT_URL=https://wlngo.top:9050\u0026#34; \\ -e \u0026#34;MINIO_DOMAIN\u0026#34;=wlngo.top \\ -v /var/opt/minio/data:/data \\ -v /opt/minio/config:/root/.minio \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ quay.io/minio/minio server \\ /data --console-address \u0026#34;:9050\u0026#34; 1 2 3 4 5 6 7 8 9 10 docker run -d -p 9000:9000 -p 9050:9050 \\ --name minio --restart=always \\ -e \u0026#34;MINIO_ROOT_USER=账号\u0026#34; \\ -e \u0026#34;MINIO_ROOT_PASSWORD=密码!\u0026#34; \\ -e \u0026#34;MINIO_DOMAIN\u0026#34;=wlngo.top \\ -v /opt/minio/data:/data \\ -v /opt/minio/config:/root/.minio \\ -e TZ=Asia/Shanghai \\ quay.io/minio/minio server \\ /data --console-address \u0026#34;:9050\u0026#34; nginx\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 upstream minio_s3 { least_conn; server 192.168.123.124:9000; } upstream minio_console { least_conn; server 192.168.123.124:9050; } server { listen 9000 ssl; listen [::]:9000 ssl; # Allow special characters in headers ignore_invalid_headers off; # Allow any size file to be uploaded. # Set to a value such as 1000m; to restrict file size to a specific value client_max_body_size 0; # Disable buffering proxy_buffering off; proxy_request_buffering off; #请填写证书文件的相对路径或绝对路径 ssl_certificate /etc/nginx/ssl/wlngo.top_nginx/wlngo.top_bundle.crt; #请填写私钥文件的相对路径或绝对路径 ssl_certificate_key /etc/nginx/ssl/wlngo.top_nginx/wlngo.top.key; ssl_session_timeout 5m; #请按照以下协议配置 ssl_protocols TLSv1.2 TLSv1.3; #请按照以下套件配置，配置加密套件，写法遵循 openssl 标准。 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_connect_timeout 300; # Default is HTTP/1, keepalive is only enabled in HTTP/1.1 proxy_http_version 1.1; proxy_set_header Connection \u0026#34;\u0026#34;; chunked_transfer_encoding off; proxy_pass http://minio_s3; # This uses the upstream directive definition to load balance } } server { listen 9050 ssl; listen [::]:9050 ssl; # Allow special characters in headers ignore_invalid_headers off; # Allow any size file to be uploaded. # Set to a value such as 1000m; to restrict file size to a specific value client_max_body_size 0; # Disable buffering proxy_buffering off; proxy_request_buffering off; #请填写证书文件的相对路径或绝对路径 ssl_certificate /etc/nginx/ssl/wlngo.top_nginx/wlngo.top_bundle.crt; #请填写私钥文件的相对路径或绝对路径 ssl_certificate_key /etc/nginx/ssl/wlngo.top_nginx/wlngo.top.key; ssl_session_timeout 5m; #请按照以下协议配置 ssl_protocols TLSv1.2 TLSv1.3; #请按照以下套件配置，配置加密套件，写法遵循 openssl 标准。 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-NginX-Proxy true; # This is necessary to pass the correct IP to be hashed real_ip_header X-Real-IP; proxy_connect_timeout 300; # To support websocket proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; chunked_transfer_encoding off; proxy_pass http://minio_console/; # This uses the upstream directive definition to load balance } } https 1.证书准备 将申请的SSL证书 .key结尾的重命名为：private.key和 .crt结尾的重命名为：public.crt 别问为什么，官方规定，不信自己看官方文档：https://min.io/docs/minio/linux/operations/network-encryption.html?ref=docs-redirect 然后将private.key和public.crt两个文件放到MinIO目录certs下面：/你的minio目录/config/certs\n监控 1 docker run -it --entrypoint=/bin/sh minio/mc 1 mc alias set myminio https://www.weiliangning.work:9000 账号 密码 1 mc admin prometheus generate myminio ","date":"2023-02-16T17:01:22.928Z","permalink":"https://wlngo.github.io/archives/docker%E5%AE%89%E8%A3%85minio/","title":"docker 安装miniO"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 docker run -d -p 9090:9090 --name prometheus \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/prometheus/config/prometheus.yml:/etc/prometheus/prometheus.yml \\ -v /var/opt/prometheus/data:/prometheus \\ prom/prometheus \\ --config.file=/etc/prometheus/prometheus.yml \\ --storage.tsdb.path=/prometheus \\ --web.console.libraries=/usr/share/prometheus/console_libraries \\ --web.enable-admin-api \\ --web.enable-lifecycle \u0026ldquo;\u0026ndash;config.file=/etc/prometheus/prometheus.yml\u0026rdquo; \u0026ldquo;\u0026ndash;storage.tsdb.path=/prometheus\u0026rdquo; \u0026ldquo;\u0026ndash;storage.tsdb.retention=24h\u0026rdquo; \u0026ldquo;\u0026ndash;web.enable-admin-api\u0026rdquo; # 控制对admin HTTP API的访问，其中包括删除时间序列等功能 \u0026ldquo;\u0026ndash;web.enable-lifecycle\u0026rdquo; node linux 监控 1 2 3 4 5 6 7 docker run -d -p 9100:9100 --name node-exporter --restart=always --net=\u0026#34;host\u0026#34; --pid=\u0026#34;host\u0026#34; \\ -v \u0026#34;/:/host:ro,rslave\u0026#34; \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ quay.io/prometheus/node-exporter:latest \\ --path.rootfs=/host mysql 监控 1 2 3 4 5 6 7 8 9 docker run -d --name mysqld-exporter --restart=always \\ -p 9104:9104 \\ -v /opt/mysqld-exporter/config/:/opt/mysqld-exporter/config/ \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ prom/mysqld-exporter:main \\ --mysqld.address=192.168.123.124:3306 \\ --config.my-cnf=/opt/mysqld-exporter/config/.my.cnf ","date":"2023-01-31T09:49:46.939Z","permalink":"https://wlngo.github.io/archives/docker%E5%AE%89%E8%A3%85prometheus/","title":"docker安装prometheus"},{"content":"下载rocketmq镜像 1 docker pull -v apache/rocketmq:5.1.3 rocketmq-nameServer 1 2 3 4 5 6 docker run -d --name rocketmq-nameServer -p 9876:9876 -p 9878:9878 \\ -e JAVA_OPT_EXT=\u0026#34;-Xms512m -Xmx512m\u0026#34; \\ -v /opt/rocketmq/nameServer/logs:/home/rocketmq/logs \\ -v /opt/rocketmq/nameServer/conf/namesrv.conf:/home/rocketmq/rocketmq-5.1.4/conf/namesrvr.conf \\ -v /opt/rocketmq/nameServer/DledgerController:/home/rocketmq/DledgerController \\ --restart=always apache/rocketmq:5.1.4 sh mqnamesrv -c /home/rocketmq/rocketmq-5.1.4/conf/namesrvr.conf rocketmq-broker 1 2 3 4 5 6 7 8 docker run -d --name rocketmq-broker \\ -e JAVA_OPT_EXT=\u0026#34;-Xms2048m -Xmx2048m\u0026#34; \\ -p 10909:10909 -p 10911:10911 -p 10912:10912 \\ -v /opt/rocketmq/broker/logs:/home/rocketmq/logs \\ -v /opt/rocketmq/broker/store/:/home/rocketmq/store/ \\ -v /opt/rocketmq/broker/conf/broker.conf:/home/rocketmq/rocketmq-5.1.4/conf/broker.conf \\ -v /opt/rocketmq/broker/conf/plain_acl.yml:/home/rocketmq/rocketmq-5.1.4/conf/plain_acl.yml \\ --restart=always apache/rocketmq:5.1.4 sh mqbroker -c /home/rocketmq/rocketmq-5.1.4/conf/broker.conf rocketmq-dashboard 需要自己编译源码 开启登录密码 地址 https://github.com/apache/rocketmq-dashboard\n1 2 3 4 5 6 7 docker run -d --name rocketmq-dashboard --ulimit nofile=1024 \\ -e JAVA_OPTS=\u0026#34;-Xms128m -Xmx128m\u0026#34; \\ -v /opt/rocketmq/rocketmq-dashboard/rocketmq-dashboard-1.0.1-SNAPSHOT.jar:/rocketmq-dashboard.jar \\ -v /opt/rocketmq/rocketmq-dashboard/config:/tmp/rocketmq-console/data/ \\ -v /opt/rocketmq/rocketmq-dashboard/logs:/root/logs \\ -p 8180:8080 --restart=always \\ apacherocketmq/rocketmq-dashboard:latest 权限 默认在conf下的plain_acl.yml https://rocketmq.apache.org/zh/docs/bestPractice/03access/#1%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D\n","date":"2023-01-10T15:38:08.812Z","permalink":"https://wlngo.github.io/archives/docker%E5%AE%89%E8%A3%85rocketmq%E9%9B%86%E7%BE%A4/","title":"docker 安装rocketmq集群"},{"content":"消耗 CPU 资源 stress 消耗 CPU 资源的方式是通过调用 sqrt 函数计算由 rand 函数产生的随机数的平方根实现的。下面的命令会产生 32 个这样的进程不断的进行计算\n1 stress -c 32 温度检测\n1 sensors ","date":"2023-01-01T19:54:49.762Z","permalink":"https://wlngo.github.io/archives/ya-li-ce-shi-wen-du-jian-ce/","title":"压力测试温度检测"},{"content":"查看内存错误\n1 grep [0-9] /sys/devices/system/edac/mc/mc*/csrow*/ch*_ce_count 1 dmesg|grep -i error 查看内存速度\n1 dmidecode -t memory ","date":"2023-01-01T17:55:18.483Z","permalink":"https://wlngo.github.io/archives/nei-cun-jian-ce-ming-ling/","title":"内存检测命令"},{"content":"如果@Parm参数为对象 并且为多参数 并且使用了bind 剩余参数即使不需要bind 也要进行绑定 否则接受不到参数\n","date":"2022-12-26T15:02:15.902Z","permalink":"https://wlngo.github.io/archives/mybatis-keng/","title":"mybatis 坑"},{"content":"\u003c!DOCTYPE html\u003e 1.1. 控制台使用 RocketMQ 提供有控制台及一系列控制台命令，用于管理员对主题，集群，broker 等信息的管理；\n登录控制台\n首先进入RocketMQ 工程，进入/RocketMQ/bin\n在该目录下有个mqadmin 脚本\n查看帮助\n在mqadmin 下可以查看有哪些命令\nsh mqadmin\n查看具体命令的使用\nsh mqadmin help 命令名称\n例如，查看updateTopic 的使用\nsh mqadmin help updateTopic\n1.2. 详细命令 1.2.1. 创建Topic 指令 updateTopic 类路径 com.alibaba.rocketmq.tools.command.topic.UpdateTopicSubCommand\n参数\n是否必填\n说明\n-b\n如果-c为空，则必填\nbroker 地址，表示topic 建在该broker\n-c\n如果-b为空，则必填\ncluster 名称，表示topic 建在该集群（集群可通过clusterList 查询）\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n-p\n否 指定新topic 的权限限制( W|R|WR )\n-r 否\n可读队列数（默认为8）\n-w\n否\n可写队列数（默认为8）\n-t\n是\nopic 名称（名称只能使用字符 ^[a-zA-Z0-9_-]+$ ）\n1.2.2. 删除Topic 指令 deleteTopic 类路径 com.alibaba.rocketmq.tools.command.topic.DeleteTopicSubCommand\n参数 是否必填\n说明\n-c\n是\ncluster 名称，表示删除某集群下的某个topic （集群可通过clusterList 查询）\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;…\n-t\n是\ntopic 名称（名称只能使用字符 ^[a-zA-Z0-9_-]+$ ）\n1.2.3. 创建（修订）订阅组 指令 updateSubGroup 类路径 com.alibaba.rocketmq.tools.command.consumer.UpdateSubGroupSubCommand\n参数\n是否必填\n说明\n-b\n如果 –c 为空，则必填\nbroker 地址，表示订阅组建在该broker\n-c\n如果 –b 为空，则必填\ncluster名称，表示topic 建在该集群（集群可通过clusterList查询）\n-d\n否 是否容许广播方式消费\n-g\n是 订阅组名\n-i\n否\n从哪个broker 开始消费\n-m\n否\n是否容许从队列的最小位置开始消费，默认会设置为false\n-q\n否\n消费失败的消息放到一个重试队列，每个订阅组配置几个重试队列\n-r 否 重试消费最大次数，超过则投递到死信队列，不再投递，并报警\n-s\n否\n消费功能是否开启\n-w 否\n发现消息堆积后，将Consumer 的消费请求重定向到另外一台Slave 机器\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.4. 删除订阅组配置 指令 deleteSubGroup 类路径 com.alibaba.rocketmq.tools.command.consumer.DeleteSubscriptionGroupCommand\n参数\n是否必填\n说明\n-b 如果–c 为空，则必填\nbroker 地址，表示订阅组建在该broker\n-c 如果–b 为空，则必填\ncluster 名称，表示topic建在该集群（集群可通过clusterList查询）\n-g\n是\n订阅组名\n-h\n否\n打印帮助\n-n 是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.5. 更新Broker 配置文件 指令 updateBrokerConfig\n类路径\ncom.alibaba.rocketmq.tools.command.broker.UpdateBrokerConfigSubCommand\n参数\n是否必填\n说明\n-b 如果–c为空，则必填\nbroker 地址，表示订阅组建在该broker\n-c 如果–b 为空，则必填\ncluster名称，表示topic 建在该集群（集群可通过clusterList查询）\n-k 是\nkey 值\n-v\n否\nvalue 值\n-h\n否\n打印帮助\n-n 是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.6. 查看Topic 列表信息 指令 topicList 类路径 com.alibaba.rocketmq.tools.command.broker.UpdateBrokerConfigSubCommand\n参数\n是否必填\n说明\n-h\n否\n打印帮助\n-n 是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.7. 查看Topic 路由信息 指令 topicRoute 类路径 com.alibaba.rocketmq.tools.command.topic.TopicRouteSubCommand\n参数\n是否必填\n说明\n-t\n是\ntopic 名称\n-h\n否\n打印帮助\n-n 是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.8. 查看Topic 统计信息 指令 topicStats 类路径\ncom.alibaba.rocketmq.tools.command.topic.TopicStatsSubCommand\n参数\n是否必填\n说明\n-t\n是\ntopic 名称\n-h\n否\n打印帮助\n-n 是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.9. 查看Broker 统计信息 指令 brokerStats 类路径\ncom.alibaba.rocketmq.tools.command.broker.BrokerStatsSubCommanD\n参数\n是否必填\n说明\n-b\n是\nbroker 地址\n-h\n否\n打印帮助\n-n 是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.10. 根据消息ID 查询消息 指令 queryMsgById 类路径\ncom.alibaba.rocketmq.tools.command.message.QueryMsgByIdSubCommand\n参数\n是否必填\n说明\n-i\n是\n消息id\n-h\n否\n打印帮助\n-n 是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.11. 根据消息Key 查询消息 指令 queryMsgByKey 类路径\ncom.alibaba.rocketmq.tools.command.message.QueryMsgByKeySubCommand\n参数\n是否必填\n说明\n-f\n否\n被查询消息的截止时间\n-k\n是\nmsgKey\n-t\n是\ntopic 名称\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.12. 根据Offset 查询消息 指令 queryMsgByOffset\n类路径\ncom.alibaba.rocketmq.tools.command.message.QueryMsgByOffsetSubCommand\n参数\n是否必填\n说明\n-b 是\nBroker 名称，表示订阅组建在该broker（这里需要注意填写的是broker 的名称，不是broker 的地址，broker名称可以在clusterList 查到\n-i\n是\nquery 队列id\n-o\n是\noffset 值\n-t\n是\ntopic 名称\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.13. 查询Producer 的网络连接 该命令只打印当前与cluster 连接的producer 网络连接信息\n指令 producerConnection\n类路径\ncom.alibaba.rocketmq.tools.command.connection.ProducerConnectionSubCommand\n参数\n是否必填\n说明\n-g\n是\n生产者所属组名\n-t\n是\ntopic 名称\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.14. 查询Consumer 的网络连接 该命令只打印当前与cluster 连接的consumer 网络连接信息\n指令 consumerConnection\n类路径\ncom.alibaba.rocketmq.tools.command.connection.ConsumerConnectionSubCommand\n参数\n是否必填\n说明\n-g\n是\n消费者所属组名\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.15. 查看订阅组消费状态 指令 consumerProgress\n类路径\ncom.alibaba.rocketmq.tools.command.consumer.ConsumerProgressSubCommand\n参数\n是否必填\n说明\n-g\n是\n消费者所属组名\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.16. 查看集群消息 指令 clusterList 类路径\ncom.alibaba.rocketmq.tools.command.cluster.ClusterListSubCommand\n参数\n是否必填\n说明\n-m\n否\n打印更多信息\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.17. 添加（更新）KV 配置信息 指令 updateKvConfig 类路径\ncom.alibaba.rocketmq.tools.command.namesrv.UpdateKvConfigCommand\n参数\n是否必填\n说明\n-k\n是\nkey 值\n-v\n是\nvalue 值\n-s\n是\nNamespace 值\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.18. 删除KV 配置信息 指令 deleteKvConfig 类路径\ncom.alibaba.rocketmq.tools.command.namesrv.DeleteKvConfigCommand\n参数\n是否必填\n说明\n-k\n是\nkey 值\n-s\n是\nNamespace 值\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.19. 添加（更新）Project group 配置信息 指令 updateProjectGroup 类路径 com.alibaba.rocketmq.tools.command.namesrv.UpdateProjectGroupCommand\n参数\n是否必填\n说明\n-p\n是\nproject group 名\n-i\n否\n服务器ip\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.20. 删除Project group 配置信息 指令 deleteProjectGroup\n类路径\ncom.alibaba.rocketmq.tools.command.namesrv.DeleteProjectGroupCommand\n参数\n是否必填\n说明\n-p\n是\nproject group 名\n-i\n否\n服务器ip\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.21. 取得Project group 配置信息 指令 getProjectGroup\n类路径\ncom.alibaba.rocketmq.tools.command.namesrv.GetProjectGroupCommand\n参数\n是否必填\n说明\n-p\n是\nproject group 名\n-i\n否\n服务器ip\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.22. 设置消费进度 根据时间来设置消费进度，设置之前要关闭这个订阅组的所有consumer，设置完再启动，方可生效\n指令 resetOffsetByTime\n类路径\ncom.alibaba.rocketmq.tools.command.offset.ResetOffsetByTimeSubCommand\n参数\n是否必填\n说明\n-f\n否\n通过时间戳强制回滚（true|false），默认为true\n-s\n是\n时间戳\n-g\n是\n消费者所属组名\n-t\n是\ntopic 名称\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.23. 清除特定Broker权限 指令 wipeWritePerm 类路径\ncom.alibaba.rocketmq.tools.command.namesrv.WipeWritePermSubCommand\n参数\n是否必填\n说明\n-b\n是\nbroker 地址\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n1.2.24. 获取Consumer消费进度 该命令只打印当前与cluster 连接的consumer 的消费进度\n指令 getConsumerStatus\n类路径 com.alibaba.rocketmq.tools.command.offset.GetConsumerStatusCommand\n参数\n是否必填\n说明\n-g\n是\n消费者所属组名\n-t\n是\n查询主题\n-i\n否\nConsumer 客户端ip\n-h\n否\n打印帮助\n-n\n是\nnameserve 服务地址列表，格式ip:port;ip:port;\u0026hellip;\n","date":"2022-12-23T15:35:01.361Z","permalink":"https://wlngo.github.io/archives/2022-12-23-15-34-59/","title":"mqadmin"},{"content":"yml @ConfigurationProperties 正确处理 maven\n","date":"2022-12-23T15:26:55.945Z","permalink":"https://wlngo.github.io/archives/springyml-pei-zhi-zhu-jie-chu-li-qi/","title":"spring yml配置注解处理器"},{"content":"rocketmq可视化\n","date":"2022-12-23T15:03:58.742Z","permalink":"https://wlngo.github.io/archives/rocketmq-dashboard/","title":"rocketmq-dashboard"},{"content":"SpringBoot 中异步多线程的MDC日志跟踪\n","date":"2022-12-23T14:59:40.962Z","permalink":"https://wlngo.github.io/archives/springboot-zhong-yi-bu-duo-xian-cheng-de-mdc-ri-zhi-gen-zong/","title":"SpringBoot 中异步多线程的MDC日志跟踪"},{"content":"将注入的Bean 放在List或者Map中:\n1 2 3 4 5 6 7 8 9 10 11 12 /* * spring会自动将 DemoService 的所有实现类bean注入到list集合 */ @Autowired private List\u0026lt;DemoService\u0026gt; demoServices; /* * 通过Map注入，通过 spring bean 的名称作为key动态获取对应实例 */ @Autowired private Map\u0026lt;String, DemoService\u0026gt; demoServiceMap; Spring在注入集合类的同时，会将集合泛型类的实例填入集合中，作为集合的初始值。 对于list、set填入的是注入类型Spring管理的实例，对于map，Spring会将service的名字作为key，对象作为value封装进入Map。\n这个过程的源码在 org.springframework.beans.factory.support.DefaultListableBeanFactory 的 doResolveDependency 方法中调用了 resolveMultipleBeans 方法：\n如果是数组，则获取数组元素类型，查找匹配该类型的所有bean，返回一个这些bean的数组； 如果该类可赋给Collection，并且是一个接口，则获取集合元素类型，查找匹配该类型的所有bean，返回一个这些bean的集合； 如果该类型是Map(注意是type == Map.class)，且key是String类型，则获取Map的value的类型，查找匹配该类型的所有bean，这是一个key为bean name、value为bean实例的一个Map，返回这个Map。 其他情况则是我们所熟知的按类型自动装配过程。 源代码具体如下(Spring版本是5.0.2)： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 @Nullable public Object doResolveDependency(DependencyDescriptor descriptor, @Nullable String beanName, @Nullable Set\u0026lt;String\u0026gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException { InjectionPoint previousInjectionPoint = ConstructorResolver.setCurrentInjectionPoint(descriptor); try { Object shortcut = descriptor.resolveShortcut(this); if (shortcut != null) { return shortcut; } Class\u0026lt;?\u0026gt; type = descriptor.getDependencyType(); Object value = getAutowireCandidateResolver().getSuggestedValue(descriptor); if (value != null) { if (value instanceof String) { String strVal = resolveEmbeddedValue((String) value); BeanDefinition bd = (beanName != null \u0026amp;\u0026amp; containsBean(beanName) ? getMergedBeanDefinition(beanName) : null); value = evaluateBeanDefinitionString(strVal, bd); } TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); return (descriptor.getField() != null ? converter.convertIfNecessary(value, type, descriptor.getField()) : converter.convertIfNecessary(value, type, descriptor.getMethodParameter())); } Object multipleBeans = resolveMultipleBeans(descriptor, beanName, autowiredBeanNames, typeConverter); if (multipleBeans != null) { return multipleBeans; } Map\u0026lt;String, Object\u0026gt; matchingBeans = findAutowireCandidates(beanName, type, descriptor); if (matchingBeans.isEmpty()) { if (isRequired(descriptor)) { raiseNoMatchingBeanFound(type, descriptor.getResolvableType(), descriptor); } return null; } String autowiredBeanName; Object instanceCandidate; if (matchingBeans.size() \u0026gt; 1) { autowiredBeanName = determineAutowireCandidate(matchingBeans, descriptor); if (autowiredBeanName == null) { if (isRequired(descriptor) || !indicatesMultipleBeans(type)) { return descriptor.resolveNotUnique(type, matchingBeans); } else { // In case of an optional Collection/Map, silently ignore a non-unique case: // possibly it was meant to be an empty collection of multiple regular beans // (before 4.3 in particular when we didn\u0026#39;t even look for collection beans). return null; } } instanceCandidate = matchingBeans.get(autowiredBeanName); } else { // We have exactly one match. Map.Entry\u0026lt;String, Object\u0026gt; entry = matchingBeans.entrySet().iterator().next(); autowiredBeanName = entry.getKey(); instanceCandidate = entry.getValue(); } if (autowiredBeanNames != null) { autowiredBeanNames.add(autowiredBeanName); } if (instanceCandidate instanceof Class) { instanceCandidate = descriptor.resolveCandidate(autowiredBeanName, type, this); } Object result = instanceCandidate; if (result instanceof NullBean) { if (isRequired(descriptor)) { raiseNoMatchingBeanFound(type, descriptor.getResolvableType(), descriptor); } result = null; } if (!ClassUtils.isAssignableValue(type, result)) { throw new BeanNotOfRequiredTypeException(autowiredBeanName, type, instanceCandidate.getClass()); } return result; } finally { ConstructorResolver.setCurrentInjectionPoint(previousInjectionPoint); } } @Nullable private Object resolveMultipleBeans(DependencyDescriptor descriptor, @Nullable String beanName, @Nullable Set\u0026lt;String\u0026gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) { Class\u0026lt;?\u0026gt; type = descriptor.getDependencyType(); if (type.isArray()) { Class\u0026lt;?\u0026gt; componentType = type.getComponentType(); ResolvableType resolvableType = descriptor.getResolvableType(); Class\u0026lt;?\u0026gt; resolvedArrayType = resolvableType.resolve(); if (resolvedArrayType != null \u0026amp;\u0026amp; resolvedArrayType != type) { type = resolvedArrayType; componentType = resolvableType.getComponentType().resolve(); } if (componentType == null) { return null; } Map\u0026lt;String, Object\u0026gt; matchingBeans = findAutowireCandidates(beanName, componentType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); Object result = converter.convertIfNecessary(matchingBeans.values(), type); if (getDependencyComparator() != null \u0026amp;\u0026amp; result instanceof Object[]) { Arrays.sort((Object[]) result, adaptDependencyComparator(matchingBeans)); } return result; } else if (Collection.class.isAssignableFrom(type) \u0026amp;\u0026amp; type.isInterface()) { Class\u0026lt;?\u0026gt; elementType = descriptor.getResolvableType().asCollection().resolveGeneric(); if (elementType == null) { return null; } Map\u0026lt;String, Object\u0026gt; matchingBeans = findAutowireCandidates(beanName, elementType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); Object result = converter.convertIfNecessary(matchingBeans.values(), type); if (getDependencyComparator() != null \u0026amp;\u0026amp; result instanceof List) { Collections.sort((List\u0026lt;?\u0026gt;) result, adaptDependencyComparator(matchingBeans)); } return result; } else if (Map.class == type) { ResolvableType mapType = descriptor.getResolvableType().asMap(); Class\u0026lt;?\u0026gt; keyType = mapType.resolveGeneric(0); if (String.class != keyType) { return null; } Class\u0026lt;?\u0026gt; valueType = mapType.resolveGeneric(1); if (valueType == null) { return null; } Map\u0026lt;String, Object\u0026gt; matchingBeans = findAutowireCandidates(beanName, valueType, new MultiElementDescriptor(descriptor)); if (matchingBeans.isEmpty()) { return null; } if (autowiredBeanNames != null) { autowiredBeanNames.addAll(matchingBeans.keySet()); } return matchingBeans; } else { return null; } } ","date":"2022-12-21T16:14:11.235Z","permalink":"https://wlngo.github.io/archives/spring-zhu-ru-bean-dao-listmap-zhong/","title":"Spring 注入 Bean 到 List / Map 中"},{"content":"idea 搜索\n1 Vulnerable declared dependency ","date":"2022-12-18T19:29:08.351Z","permalink":"https://wlngo.github.io/archives/idea-ping-bi-cev-jian-ce/","title":"idea 屏蔽cev检测"},{"content":"https://github.com/chaifeng/ufw-docker\n","date":"2022-12-18T19:27:27.389Z","permalink":"https://wlngo.github.io/archives/ufw-he-docker-chong-tu-wen-ti/","title":"ufw 和docker 冲突问题"},{"content":"打开管理页面 打开chrome浏览器，地址栏输入以下协议并回车\n1 chrome://net-internals/#hsts 浏览器中将会出现以下页面，可以通过以下操作将已经自动转https协议的域名从chrome中移除\nDomain Security Prolicy Delete remain security prolicies ","date":"2022-12-16T15:44:51.649Z","permalink":"https://wlngo.github.io/archives/chrome-jie-jue-http-zi-dong-tiao-zhuan-https-wen-ti/","title":"chrome解决http自动跳转https问题"},{"content":"工厂模式\n","date":"2022-12-11T22:03:00.603Z","permalink":"https://wlngo.github.io/archives/she-ji-mo-shi-gong-chang-mo-shi/","title":"设计模式 工厂模式"},{"content":"https://hub.docker.com/r/yapipro/yapi\n","date":"2022-11-27T22:23:20.927Z","permalink":"https://wlngo.github.io/archives/dcoker-an-zhuang-yapi/","title":"Dcoker 安装 yapi"},{"content":"★★全家桶一键激活★★★ https://wws.lanzouh.com/b03j22eta 密码:3kqv win/mac/linux全部在内 下载解压打开对应的文件夹 有教程说明 2018-2021版本激活以后2099年到期 2022版本激活可以激活到2025年 请按所需激活软件！。 祝您今天好心情，工作顺利，生活甜美！\n","date":"2022-09-04T18:01:52.986Z","permalink":"https://wlngo.github.io/archives/ruan-jian/","title":"软件"},{"content":"官方文档：http://openresty.org/cn/\n官方文档api：https://openresty-reference.readthedocs.io/en/latest/Directives/\n官方文档博客: https://blog.openresty.com.cn/cn/\n","date":"2022-09-01T14:44:36.567Z","permalink":"https://wlngo.github.io/archives/openresty/","title":"openresty"},{"content":"官方文档 https://www.jfrog.com/confluence/display/JFROG/Installing%20Artifactory 安装\n1 2 3 4 5 6 7 8 9 10 11 12 mkdir -p $JFROG_HOME/artifactory-jcr mkdir -p $JFROG_HOME/artifactory-oss mkdir -p $JFROG_HOME/artifactory-oss/var/etc/ cd $JFROG_HOME/artifactory-oss/var/etc/ touch ./system.yaml chown -R 1030:1030 $JFROG_HOME/artifactory-oss/var mkdir -p $JFROG_HOME/artifactory-jcr/var/etc/ cd $JFROG_HOME/artifactory-jcr/var/etc/ touch ./system.yaml chown -R 1030:1030 $JFROG_HOME/artifactory-jcr/var docker run --restart=always --name artifactory-oss -v $JFROG_HOME/artifactory-oss/var/:/var/opt/jfrog/artifactory -d -p 8010:8081 -p 8020:8082 releases-docker.jfrog.io/jfrog/artifactory-oss:7.49.10 docker run --restart=always --name artifactory-jcr -v $JFROG_HOME/artifactory-jcr/var/:/var/opt/jfrog/artifactory -d -p 8030:8081 -p 8040:8082 releases-docker.jfrog.io/jfrog/artifactory-jcr:7.49.10 nginx 代理端口要保持一致 配置需要从管理页面下载\n限制内存 system.yaml\n1 2 shared: extraJavaOpts: \u0026#34;-server -Xms512m -Xmx2g -Xss256k -XX:+UseG1GC\u0026#34; ","date":"2022-08-03T10:29:54.757Z","permalink":"https://wlngo.github.io/archives/jfrogjava-er-jin-zhi-bao-guan-li-gong-ju/","title":"JFROG java 二进制包管理工具"},{"content":"拉取镜像 1 docker pull mongo 1 docker pull mongo 运行容器 1 2 docker run --name some-mongo -d --net mongo -p 27017:27017 --restart=on-fa ilure:3 mongo 可视化web 1 docker run -d --name mongo-express --net mongo -e ME_CONFIG_MONGODB_SERVER=some-mongo -p 8081:8081 --restart=always mongo-express ","date":"2022-08-01T18:11:44.253Z","permalink":"https://wlngo.github.io/archives/docker-an-zhuang-mongodb/","title":"docker 安装  mongodb"},{"content":" 1 -Xshare:off --add-opens java.base/java.util=ALL-UNNAMED ","date":"2022-07-31T11:52:27.965Z","permalink":"https://wlngo.github.io/archives/jdk17-xu-ni-ji-can-shu/","title":"JDK 17 虚拟机参数"},{"content":"官网文档 https://docs.gitlab.cn/jh/install/docker.html\n命令(最新版本16.2.1)\n1 2 3 4 5 6 7 8 9 10 sudo docker run --detach \\ --hostname www.wlngo.top \\ --publish 8443:8443 --publish 8480:80 --publish 8422:22 --publish 8450:8450\\ --name gitlab \\ --restart always \\ --volume $GITLAB_HOME/config:/etc/gitlab \\ --volume $GITLAB_HOME/logs:/var/log/gitlab \\ --volume $GITLAB_HOME/data:/var/opt/gitlab \\ --shm-size 256m \\ gitlab/gitlab-ee:17.0.2-ee.0 1 sudo docker exec -it gitlab grep \u0026#39;Password:\u0026#39; /etc/gitlab/initial_root_password https://docs.gitlab.cn/omnibus/settings/smtp.html#qq-exmail\n1 2 #邮箱发件人名字 gitlab_rails[\u0026#39;gitlab_email_display_name\u0026#39;] = \u0026#39;魏亮宁\u0026#39; 1 2 3 4 docker exec -it gitlab /bin/bash gitlab-ctl reconfigure gitlab-rails console Notify.test_email(\u0026#39;2252603132@qq.com\u0026#39;,\u0026#39;test\u0026#39;,\u0026#39;test\u0026#39;).deliver_now ","date":"2022-07-30T11:23:46.585Z","permalink":"https://wlngo.github.io/archives/docker-an-zhuang-gitlab/","title":"docker 安装 gitlab"},{"content":"下载镜像 1 docker pull jenkins/jenkins:lts-jdk11 运行镜像(不必限制内存 ) 1 2 3 4 5 docker run -d --name jenkins -p 8050:8080 -p 50000:50000 \\ -v /opt/jenkins_home:/var/jenkins_home -v /root/.m2:/root/.m2 -uroot \\ -v /root/tls/docker/:/root/tls/docker \\ -e JAVA_OPTS:\u0026#34;-Xmx4g -Xms4g\u0026#34;--restart=always \\ weiliangning.work:18040/docker/jenkins/jenkins:lts-jdk17 默认安装 配置全局工具 jdk git maven 配置插件 github maven ssh 设置maven 阿里云代理配置 默认路径在 账号Jenkins（默认进入容器账号） ~ 根路径下.m2 隐藏文件 设置github 服务器 凭据获取 、\nWebhooks钩子函数 构建后执行脚本 ","date":"2022-07-30T11:14:50.437Z","permalink":"https://wlngo.github.io/archives/docker-an-zhuang-jenkins/","title":"docker 安装jenkins"},{"content":"拉去镜像 1 docker pull logstash:8.6.0 运行logstash 1 2 3 4 5 6 7 docker run -d -it --name logstash --net elknetwork \\ -p 5044:5044 -p 9600:9600 --restart=always \\ -v /opt/javarun/:/opt/javarun \\ -v /opt/elk/logstash/data:/usr/share/logstash/data \\ -v /opt/elk/logstash/pipeline/:/usr/share/logstash/pipeline/ \\ -v /opt/elk/logstash/config/:/usr/share/logstash/config/ \\ logstash:8.6.0 ","date":"2022-07-30T11:05:13.463Z","permalink":"https://wlngo.github.io/archives/docker-an-zhuang-logstash833/","title":"docker 安装Logstash:8.6.0"},{"content":"Halo 博客官网文档 https://docs.halo.run/\ndocker 运行命令 1 2 3 4 5 6 7 docker run -it -d --name halo -p 8090:8090 \\ -v ~/.halo2:/root/.halo2 -e JVM_OPTS=\u0026#34;-Xmx1024m -Xms1024m\u0026#34; \\ registry.fit2cloud.com/halo/halo:2.20 \\ --spring.r2dbc.url=r2dbc:pool:mysql://192.168.123.124:3306/halo2 \\ --spring.r2dbc.username=root \\ --spring.r2dbc.password=password \\ --spring.sql.init.platform=mysql ","date":"2022-07-30T10:53:08.301Z","permalink":"https://wlngo.github.io/archives/halo-bo-ke-da-jian-he-qian-yi/","title":"Halo 博客搭建和迁移"},{"content":"https://www.cnblogs.com/lgx5/p/10732016.html\n","date":"2022-07-28T23:15:53.332Z","permalink":"https://wlngo.github.io/archives/npm-an-zhuang/","title":"npm 安装"},{"content":"下载镜像 1 docker pull kibana:8.6.0 创建docke网络 1 docker network create elknetwork 运行镜像 1 2 3 4 5 6 7 8 9 docker run -d --name kibana --restart=always -p 5601:5601 \\ -v /opt/elk/kibana/config/:/usr/share/kibana/config/ \\ -v /opt/elk/kibana/data/:/usr/share/kibana/data/ \\ -v /opt/elk/kibana/plugins/:/usr/share/kibana/plugins/ \\ -v /opt/elk/kibana/logs/:/usr/share/kibana/logs/ \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ kibana:8.6.0 先使用默认的Elasticsearch https 的设置 不做修改 后面改为http 不然 kibana 无法启动 进入elasticsearch 镜像生产token 1 docker exec -it elasticsearch /bin/bash 1 sh bin/elasticsearch-create-enrollment-token --scope kibana kibana配置文件必须为默认的 才能设置(物理机选择账号密码安装) 1 2 3 4 5 # Default Kibana configuration for docker target server.host: \u0026#34;0.0.0.0\u0026#34; server.shutdownTimeout: \u0026#34;5s\u0026#34; elasticsearch.hosts: [ \u0026#34;http://elasticsearch:9200\u0026#34; ] monitoring.ui.container.elasticsearch.enabled: true 进入kibana 镜像获取验证码 1 docker exec -it kibana /bin/bash 1 sh bin/kibana-verification-code 修改Elasticsearch 密码 1 docker exec -it elasticsearch /bin/bash 1 sh bin/elasticsearch-reset-password --username elastic -i 生成插件加密密钥并 添加到 kibana.yml 1 docker exec -it kibana /bin/bash 1 sh bin/kibana-encryption-keys generate 修改 kibana 为中文 和修改es地址（否则导致重启后无法成功启动 修改为http协议） 1 docker cp kibana:/usr/share/kibana/config/kibana.yml ~ 修改ip为容器域名 修改为http协议 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # # ** THIS IS AN AUTO-GENERATED FILE ** # # Default Kibana configuration for docker target #server.host: \u0026#34;0.0.0.0\u0026#34; #server.shutdownTimeout: \u0026#34;5s\u0026#34; #elasticsearch.hosts: [ \u0026#34;http://elasticsearch:9200\u0026#34; ] #monitoring.ui.container.elasticsearch.enabled: true ### \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; BACKUP END: Kibana interactive setup (2022-07-30T02:22:45.284Z) # This section was automatically generated during setup. server.host: 0.0.0.0 server.shutdownTimeout: 5s elasticsearch.hosts: [\u0026#39;http://elasticsearch:9200\u0026#39;] monitoring.ui.container.elasticsearch.enabled: true elasticsearch.serviceAccountToken: AAEAAWVsYXN0aWMva2liYW5hL2Vucm9sbC1wcm9jZXNzLXRva2VuLTE2NTkxNDc3NjQ1NTc6NTdaNWtlOHJULXlSWkFfaVg2WWdSUQ elasticsearch.ssl.certificateAuthorities: [/usr/share/kibana/data/ca_1659147765281.crt] xpack.fleet.outputs: [{id: fleet-default-output, name: default, is_default: true, is_default_monitoring: true, type: elasticsearch, hosts: [\u0026#39;http://elasticsearch:9200\u0026#39;], ca_trusted_fingerprint: 9983b684a10b3cbc24e1c5816d911bdcdb323545fb36bb5fc3f685f3214efae9}] #中文 i18n.locale: \u0026#34;zh-CN\u0026#34; xpack.encryptedSavedObjects.encryptionKey: b363ba8a4cba829a212a9b1202ea2bb7 xpack.reporting.encryptionKey: b98e56b7304314427f71ec57d1a9d53d xpack.security.encryptionKey: dc7505bc23e41561e586a025e4d83a45 1 docker cp kibana.yml kibana:/usr/share/kibana/config/kibana.yml 修改Elasticsearch 为http 协议 1 docker exec -it elasticsearch /bin/bash 1 docker cp elasticsearch:/usr/share/elasticsearch/config/elasticsearch.yml ~ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 cluster.name: \u0026#34;docker-cluster\u0026#34; network.host: 0.0.0.0 #----------------------- BEGIN SECURITY AUTO CONFIGURATION ----------------------- # # The following settings, TLS certificates, and keys have been automatically # generated to configure Elasticsearch security features on 30-07-2022 02:12:38 # # -------------------------------------------------------------------------------- # Enable security features xpack.security.enabled: true xpack.security.enrollment.enabled: true # Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agents xpack.security.http.ssl: enabled: false keystore.path: certs/http.p12 # Enable encryption and mutual authentication between cluster nodes xpack.security.transport.ssl: enabled: true verification_mode: certificate keystore.path: certs/transport.p12 truststore.path: certs/transport.p12 #----------------------- END SECURITY AUTO CONFIGURATION ------------------------- 1 docker cp elasticsearch.yml elasticsearch:/usr/share/elasticsearch/config/elasticsearch.yml 重启容器 ","date":"2022-07-28T20:19:12.545Z","permalink":"https://wlngo.github.io/archives/docker-an-zhuang-kibana832/","title":"docker 安装 kibana:8.6.0"},{"content":"下载镜像 1 docker pull elasticsearch:8.6.0 创建docke网络 1 docker network create elknetwork 运行镜像 1 2 3 4 5 6 7 8 9 10 docker run -d --name elasticsearch --restart=always \\ -p 9200:9200 -p 9300:9300 -e \u0026#34;discovery.type=single-node\u0026#34; \\ -e TZ=Asia/Shanghai \\ -v /etc/timezone:/etc/timezone:ro \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/elk/elasticsearch/config:/usr/share/elasticsearch/config \\ -v /opt/elk/elasticsearch/data:/usr/share/elasticsearch/data \\ -v /opt/elk/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\ -v /opt/elk/elasticsearch/logs:/usr/share/elasticsearch/logs \\ elasticsearch:8.6.0 ","date":"2022-07-28T20:17:55.962Z","permalink":"https://wlngo.github.io/archives/docker-an-zhuang-elasticsearch832/","title":"docker 安装Elasticsearch:8.6.0"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/bin/bash REPO_URL=\u0026#39;http://10.33.6.49:8081/repository/yapi_npm/\u0026#39; USERNAME=\u0026#39;admin\u0026#39; PASSWORD=\u0026#39;admin123\u0026#39; MULU=\u0026#39;/home/keyvalue/Documents/node_modules\u0026#39; HASFILE=\u0026#39;package.json\u0026#39; for file in \u0026#34;$MULU\u0026#34;/*; do if [ -d \u0026#34;$file\u0026#34; ]; then # echo $file #这里写上传代码 $file是目录名 if [ -f \u0026#34;$file/$HASFILE\u0026#34; ];then echo \u0026#34;$file/$HASFILE\u0026#34; cd \u0026#34;$file\u0026#34; npm publish --registry \u0026#34;$REPO_URL\u0026#34; fi; fi; done ","date":"2022-07-14T19:07:21.188Z","permalink":"https://wlngo.github.io/archives/nexus3-pi-liang-dao-ru-npm-bao/","title":"nexus3 批量导入npm包"},{"content":"https://hub.docker.com/\n","date":"2022-07-13T20:45:11.964Z","permalink":"https://wlngo.github.io/archives/dockerhub-guan-wang/","title":"Docker hub 官网"},{"content":"设置nexus3 混合仓库\n允许重新部署和更新 批量导入shell脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/bin/bash # copy and run this script to the root of the repository directory containing files # this script attempts to exclude uploading itself explicitly so the script name is important # Get command line params while getopts \u0026#34;:r:u:p:\u0026#34; opt; do case $opt in r) REPO_URL=\u0026#34;$OPTARG\u0026#34; ;; u) USERNAME=\u0026#34;$OPTARG\u0026#34; ;; p) PASSWORD=\u0026#34;$OPTARG\u0026#34; ;; esac done find . -type f -not -path \u0026#39;./mavenimport\\.sh*\u0026#39; -not -path \u0026#39;*/\\.*\u0026#39; -not -path \u0026#39;*/\\^archetype\\-catalog\\.xml*\u0026#39; -not -path \u0026#39;*/\\^maven\\-metadata\\-local*\\.xml\u0026#39; -not -path \u0026#39;*/\\^maven\\-metadata\\-deployment*\\.xml\u0026#39; | sed \u0026#34;s|^\\./||\u0026#34; | xargs -I \u0026#39;{}\u0026#39; curl -u \u0026#34;$USERNAME:$PASSWORD\u0026#34; -X PUT -v -T {} ${REPO_URL}/{} ; 可以命名为mavenimport.sh\n使用方法 ./mavenimport.sh -u 你的nexus3账号 -p 你的nexus3密码 -r 仓库地址\n","date":"2022-07-13T17:45:35.139Z","permalink":"https://wlngo.github.io/archives/nexus3-pi-liang-dao-ru-jar-bao/","title":"nexus3 批量导入jar包"},{"content":"#Apache POI\n描述： 强大操作word 和excel工具，支持各种复杂数据导出导出\njar 包关系结构 常用maven 依赖网址 https://mvnrepository.com/artifact/org.apache.poi/poi\n（旧版本 word 和excel） https://mvnrepository.com/artifact/org.apache.poi/poi-ooxml （新版本 word 和excel）\nEasypoi 描述： easypoi功能如同名字easy,主打的功能就是容易,让一个没见接触过poi的人员 就可以方便的写出Excel导出,Excel模板导出,Excel导入,Word模板导出,通过简单的注解和模板 语言(熟悉的表达式语法),完成以前复杂的写法\nmaven 依赖网址 官网 http://doc.wupaas.com/docs/easypoi/easypoi-1c0u4mo8p4ro8\n官方文档 http://easypoi.mydoc.io/#text_217736\nmaven 依赖网址（spring boot） https://mvnrepository.com/artifact/cn.afterturn/easypoi-spring-boot-starter\nEasyExcel 描述： JAVA解析Excel工具EasyExcel ali系开源产品\n官网文档 https://easyexcel.opensource.alibaba.com/\nmaven 依赖网址（spring boot） https://mvnrepository.com/artifact/com.alibaba/easyexcel\n","date":"2022-07-11T15:08:00.589Z","permalink":"https://wlngo.github.io/archives/java%E6%93%8D%E4%BD%9Cword%E5%92%8Cexcel/","title":"Java 操作word 和excel"},{"content":"安装命令 拉取镜像\n1 docker pull jacekkow/gitblit 启动镜像\n1 2 3 4 sudo docker run -d --name gitblit -v /opt/gitblit-data:/opt/gitblit-data -p 8443:8443 -p 8080:8080 -p 9418:9418 -p 29418:29418 --restart=always jacekkow/gitblit ","date":"2022-07-09T22:12:22.074Z","permalink":"https://wlngo.github.io/archives/docker%E5%AE%89%E8%A3%85gitblit/","title":"Docker 安装git 私服 gitblit"}]